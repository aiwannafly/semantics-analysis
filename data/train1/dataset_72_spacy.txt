# text =  Вчера OpenAI выпустили Whisper.
Вчера O
OpenAI B-TERM
выпустили O
Whisper B-TERM
. O

# text =  По сути авторы попытались: Исключить транскрипты других систем ASR из датасета; Привести пунктуации к некому стандарту.
По O
сути O
авторы O
попытались O
: O
Исключить O
транскрипты O
других O
систем O
ASR B-TERM
из O
датасета; O
Привести O
пунктуации O
к O
некому O
стандарту O
. O

# text =  Серьезной нормализации или денормализации текста не делалось.
Серьезной O
нормализации B-TERM
или O
денормализации B-TERM
текста O
не O
делалось O
. O

# text =  Под капотом же seq2seq модель, глядишь сама всё и так выучит.
Под O
капотом O
же O
seq2seq B-TERM
модель O
, O
глядишь O
сама O
всё O
и O
так O
выучит O
. O

# text =  Ведь исходя из названий FAIR, OpenAI и прочие же FOSS - альтруисты, борющиеся за наше будущее, они же выложили код для тренировки (а повторить смогут лишь GAFA компании) и все датасеты, не так ли?
Ведь O
исходя O
из O
названий O
FAIR B-TERM
, O
OpenAI B-TERM
и O
прочие O
же O
FOSS B-TERM
- O
альтруисты O
, O
борющиеся O
за O
наше O
будущее O
, O
они O
же O
выложили O
код O
для O
тренировки O
( O
а O
повторить O
смогут O
лишь O
GAFA B-TERM
компании O
) O
и O
все O
датасеты O
, O
не O
так O
ли O
? O

# text =  На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.
На O
практике O
OpenAI B-TERM
уже O
давно O
не O
Open O
, O
а O
недавняя O
история O
с O
DALLE-2 B-TERM
/ O
Midjourney B-TERM
/ O
Stable B-TERM
Diffusion I-TERM
скорее O
иллюстрируют O
тренд O
. O

# text =  Наверное стоит только сказать, что это sequence-to-sequence encoder-decoder трансформерная модель, без особого снижения длины инпута с довольном стандартным окном в 25 миллисекунд и шагом в 10 миллисекунд, работающая на аудио в 16 килогерц.
Наверное O
стоит O
только O
сказать O
, O
что O
это O
sequence B-TERM
- I-TERM
to I-TERM
- I-TERM
sequence I-TERM
encoder I-TERM
- I-TERM
decoder I-TERM
трансформерная O
модель O
, O
без O
особого O
снижения O
длины O
инпута O
с O
довольном O
стандартным O
окном O
в O
25 O
миллисекунд O
и O
шагом O
в O
10 O
миллисекунд O
, O
работающая O
на O
аудио O
в O
16 O
килогерц O
. O

# text =  Решать конечно вам для вашего конкретного приложения, но если сравнивать только саму модель распознавания, а не весь обвес в виде сервиса (понятно, что тут VAD и детектор языка запихали тоже в модель), например с древними бенчмарками из silero-models, то самые маленькие модели на CPU в расчете на 1 ядро (1 ядро = 2 потока) отличаются по скорости … на два порядка.
Решать O
конечно O
вам O
для O
вашего O
конкретного O
приложения O
, O
но O
если O
сравнивать O
только O
саму O
модель O
распознавания O
, O
а O
не O
весь O
обвес O
в O
виде O
сервиса O
( O
понятно O
, O
что O
тут O
VAD B-TERM
и O
детектор O
языка O
запихали O
тоже O
в O
модель O
) O
, O
например O
с O
древними O
бенчмарками O
из O
silero B-TERM
- I-TERM
models I-TERM
, O
то O
самые O
маленькие O
модели O
на O
CPU O
в O
расчете O
на O
1 O
ядро O
( O
1 O
ядро O
= O
2 O
потока O
) O
отличаются O
по O
скорости O
… O
на O
два O
порядка O
. O

# text =  Для наших моделей из прошлого релиза, многие из этих датасетов тоже как бы "zero-shot" (то есть у нас нет соответствующего большого тренировочного датасета).
Для O
наших O
моделей O
из O
прошлого O
релиза O
, O
многие O
из O
этих O
датасетов O
тоже O
как O
бы O
" O
zero B-TERM
- I-TERM
shot I-TERM
" O
( O
то O
есть O
у O
нас O
нет O
соответствующего O
большого O
тренировочного O
датасета O
) O
. O
