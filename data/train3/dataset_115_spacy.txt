# text = Анализ тональности текста с использованием фреймворка Lightautoml 
Анализ B-TERM
тональности I-TERM
текста I-TERM
с O
использованием O
фреймворка O
Lightautoml B-TERM

# text = Сентиментный анализ (анализ тональности) – это область компьютерной лингвистики, занимающаяся изучением эмоций в текстовых документах, в основе которой лежит машинное обучение.
Сентиментный B-TERM
анализ I-TERM
( O
анализ B-TERM
тональности I-TERM
) O
– O
это O
область O
компьютерной O
лингвистики O
, O
занимающаяся O
изучением O
эмоций O
в O
текстовых O
документах O
, O
в O
основе O
которой O
лежит O
машинное O
обучение O
. O

# text = В этой статье я покажу, как мы использовали для этих целей внутреннюю разработку компании – фреймворк LightAutoML, в котором имеется всё для решения поставленной задачи – предобученные готовые векторные представления слов FastText и готовые текстовые пресеты, в которых необходимо только указать гиперпараметры.
В O
этой O
статье O
я O
покажу O
, O
как O
мы O
использовали O
для O
этих O
целей O
внутреннюю O
разработку O
компании O
– O
фреймворк O
LightAutoML B-TERM
, O
в O
котором O
имеется O
всё O
для O
решения O
поставленной O
задачи O
– O
предобученные B-TERM
готовые I-TERM
векторные I-TERM
представления I-TERM
слов I-TERM
FastText B-TERM
и O
готовые O
текстовые O
пресеты O
, O
в O
которых O
необходимо O
только O
указать O
гиперпараметры O
. O

# text =  При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.
При O
обучении O
модели O
значение O
метрики O
F1-score B-TERM
достигло O
0.894 B-TERM
, O
соответственно O
можно O
сделать O
вывод O
о O
том O
, O
что O
модель O
хорошо O
справляется O
с O
задачей O
определения B-TERM
нейтральных I-TERM
и I-TERM
негативных I-TERM
обращений I-TERM
. O

# text =  Также одним из способов оценить работу модели в целом можно по кривой ROC-AUC, которая описывает площадь под кривой (Area Under Curve – Receiver Operating Characteristic).
Также O
одним O
из O
способов O
оценить O
работу O
модели O
в O
целом O
можно O
по O
кривой O
ROC B-TERM
- I-TERM
AUC I-TERM
, O
которая O
описывает O
площадь O
под O
кривой O
( O
Area B-TERM
Under I-TERM
Curve I-TERM
– I-TERM
Receiver I-TERM
Operating I-TERM
Characteristic I-TERM
) O
. O

# text =  В качестве подтверждения вышесказанного можно привести работу встроенного в LAMA модуля – LIME, который раскрывает работу модели окрашивая слова в тот или иной цвет, в зависимости от их эмоционального окраса.
В O
качестве O
подтверждения O
вышесказанного O
можно O
привести O
работу O
встроенного O
в O
LAMA B-TERM
модуля O
– O
LIME B-TERM
, O
который O
раскрывает O
работу O
модели O
окрашивая O
слова O
в O
тот O
или O
иной O
цвет O
, O
в O
зависимости O
от O
их O
эмоционального O
окраса O
. O

# text =  Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.
Также O
фреймворк O
может O
решать O
задачи O
регрессионного B-TERM
анализа I-TERM
, O
целью O
которого O
является O
определение B-TERM
зависимости I-TERM
между I-TERM
переменными I-TERM
и O
оценкой B-TERM
функции I-TERM
регрессии I-TERM
. O

# text =  .Работа с текстомВ LightAutoML имеется большое количество вариантов разработки той или иной модели, работающей с текстом.
.Работа O
с O
текстомВ O
LightAutoML B-TERM
имеется O
большое O
количество O
вариантов O
разработки O
той O
или O
иной O
модели O
, O
работающей O
с O
текстом O
. O

# text =  Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги
Библиотека O
предоставляет O
не O
только O
получение O
стандартных O
признаков O
на O
основе O
TF B-TERM
- I-TERM
IDF I-TERM
, O
но O
и O
на O
основе O
эмбеддингов O
: O
1 O
) O
На O
основе O
встроенного O
FastText B-TERM
, O
который O
можно O
тренировать O
на O
том O
или O
ином O
корпусе O
2 O
) O
Предобученных O
моделей O
Gensim3 B-TERM
) O
Любой O
другой O
объект O
, O
который O
имеет O
вид O
словаря O
, O
где O
на O
вход O
подается O
слово O
, O
а O
на O
выходе O
его O
эмбеддинги O

# text = Среди используемых стратегий извлечения представлений текстов из эмбеддингов слов, можно выделить:1) Weighted Average Transformer (WAT) – взвешивается каждое слово с некоторым весом
Среди O
используемых O
стратегий O
извлечения O
представлений O
текстов O
из O
эмбеддингов O
слов O
, O
можно O
выделить:1 O
) O
Weighted B-TERM
Average I-TERM
Transformer I-TERM
( O
WAT B-TERM
) O
– O
взвешивается O
каждое O
слово O
с O
некоторым O
весом O
			
# text = Bag of Random Embedding Projections (BOREP) – строится линейная модель со случайными весами  
Bag B-TERM
of I-TERM
Random I-TERM
Embedding I-TERM
Projections I-TERM
( O
BOREP O
) O
– O
строится O
линейная O
модель O
со O
случайными O
весами O

# text = Bert Pooling – получение эмбеддинга с последнего выхода модели Transformer  
Bert B-TERM
Pooling I-TERM
– O
получение O
эмбеддинга O
с O
последнего O
выхода O
модели O
Transformer B-TERM

# text = За препроцессинг текста отвечает класс токенайзера, по умолчанию применяется только для TF-IDF.
За O
препроцессинг O
текста O
отвечает O
класс O
токенайзера O
, O
по O
умолчанию O
применяется O
только O
для O
TF B-TERM
- I-TERM
IDF I-TERM
. O

# text = Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.
Подводя O
итоги O
стоит O
сказать O
, O
что O
LightAutoML O
благодаря O
встроенному O
инструментарию O
способен O
показывать O
достаточно O
хорошие O
результаты O
в O
задачах O
бинарной O
или O
мультиклассовой B-TERM
классификации I-TERM
и O
регрессии O
. O

# text = Конкретно в нашем случае нам удалось создать модель сентиментного анализа, которая с 89% точностью определяет эмоциональный окрас обращения и слова, которые оказывают на это наибольшее влияние.
Конкретно O
в O
нашем O
случае O
нам O
удалось O
создать O
модель O
сентиментного O
анализа O
, O
которая O
с O
89 B-TERM
% I-TERM
точностью B-TERM
определяет O
эмоциональный O
окрас O
обращения O
и O
слова O
, O
которые O
оказывают O
на O
это O
наибольшее O
влияние O
. O
