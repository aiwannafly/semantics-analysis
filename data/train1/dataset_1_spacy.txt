# text =  1 January 2010 at 07:59 Заметки об NLP (часть 2) Artificial Intelligence Natural Language Processing.
1 O
January O
2010 O
at O
07:59 O
Заметки O
об O
NLP B-TERM
( O
часть O
2 O
) O
Artificial B-TERM
Intelligence I-TERM
Natural B-TERM
Language I-TERM
Processing I-TERM
. O


# text =  Хотя в первой части я и говорил, что не собираюсь останавливаться на морфологии, видимо, совсем без неё не получится
Хотя O
в O
первой O
части O
я O
и O
говорил O
, O
что O
не O
собираюсь O
останавливаться O
на O
морфологии B-TERM
, O
видимо O
, O
совсем O
без O
неё O
не O
получится O
. O

# text =  Всё-таки обработка предложений сильно завязана на предшествующий морфологический анализ.
Всё O
- O
таки O
обработка O
предложений O
сильно O
завязана O
на O
предшествующий O
морфологический B-TERM
анализ I-TERM
. O

# text =  Наш с вами родной русский язык очень хорош (для нас) и труден (для иностранцев) богатой фонетикой и разнообразием грамматических средств.
Наш O
с O
вами O
родной O
русский O
язык O
очень O
хорош O
( O
для O
нас O
) O
и O
труден O
( O
для O
иностранцев O
) O
богатой O
фонетикой B-TERM
и O
разнообразием O
грамматических B-TERM
средств I-TERM
. O


# text =  Во-первых, в них не так много незнакомых нам фонем.
Во O
- O
первых O
, O
в O
них O
не O
так O
много O
незнакомых O
нам O
фонем B-TERM
. O


# text =  Во-вторых, обилие грамматических явлений редко сталкивает нас с чем-либо непонятным.
Во O
- O
вторых O
, O
обилие O
грамматических B-TERM
явлений I-TERM
редко O
сталкивает O
нас O
с O
чем O
- O
либо O
непонятным O
. O

# text =  А для американца, например, само понятие рода или падежа совершенно неочевидно.
А O
для O
американца O
, O
например O
, O
само O
понятие O
рода B-TERM
или O
падежа B-TERM
совершенно O
неочевидно O
. O

# text =  Теперь о морфологии.
Теперь O
о O
морфологии B-TERM
. O


# text =  Автоматические морфологические анализаторы работают хорошо.
Автоматические B-TERM
морфологические I-TERM
анализаторы I-TERM
работают O
хорошо O
. O



# text =  Если кому интересно посмотреть, как работает автоматический анализатор — можно поэкспериментировать на сайте С.А. Старостина.
Если O
кому O
интересно O
посмотреть O
, O
как O
работает O
автоматический B-TERM
анализатор B-TERM
— O
можно O
поэкспериментировать O
на O
сайте O
С.А. B-TERM
Старостина I-TERM
. O

# text =  Смею предположить, что едва ли не все морфологические анализаторы русского так или иначе опираются на Грамматический словарь Зализняка.
Смею O
предположить O
, O
что O
едва O
ли O
не O
все O
морфологические O
анализаторы O
русского O
так O
или O
иначе O
опираются O
на O
Грамматический B-TERM
словарь I-TERM
Зализняка I-TERM
. O

# text =  Сам я пользуюсь разработками Алексея Сокирко, «обёрнутыми» в удобный интерфейс на сайте Lemmatizer.
Сам O
я O
пользуюсь O
разработками O
Алексея B-TERM
Сокирко I-TERM
, O
« O
обёрнутыми O
» O
в O
удобный O
интерфейс O
на O
сайте O
Lemmatizer B-TERM
. O


# text =  Судите сами: упомянутый русский морфологический анализатор Алексея Сокирко оперирует базой данных в 18,5 мегабайт.
Судите O
сами O
: O
упомянутый O
русский B-TERM
морфологический I-TERM
анализатор I-TERM
Алексея I-TERM
Сокирко I-TERM
оперирует O
базой O
данных O
в O
18,5 O
мегабайт O
. O

# text =  На Грамоте предлагают относить их к «предикативам», но общепринятого подхода нет.
На O
Грамоте B-TERM
предлагают O
относить O
их O
к O
« O
предикативам O
» O
, O
но O
общепринятого O
подхода O
нет O
. O

# text =  Например, ещё одна «фича» анализатора Сокирко: он называет глаголы в личной форме («бегаю») глаголами, а в начальной форме («бегать») — инфинитивами.
Например O
, O
ещё O
одна O
« O
фича O
» O
анализатора B-TERM
Сокирко I-TERM
: O
он O
называет O
глаголы O
в O
личной O
форме O
( O
« O
бегаю O
» O
) O
глаголами O
, O
а O
в O
начальной O
форме O
( O
« O
бегать O
» O
) O
— O
инфинитивами O
. O



# text =  Tags: NLP, обработка текстовб, компьютерная лингвистика.
Tags O
: O
NLP B-TERM
, O
обработка B-TERM
текстов
, O
компьютерная B-TERM
лингвистика I-TERM


# text =  Туториал по фреймворку для программирования датасетов MTS AI corporate blog.
Туториал O
по O
фреймворку O
для O
программирования O
датасетов O
MTS B-TERM
AI I-TERM
corporate B-TERM
blog I-TERM


# text =  Я Игорь Буянов, старший разработчик группы разметки данных MTS AI.
Я O
Игорь B-TERM
Буянов I-TERM
, O
старший O
разработчик O
группы O
разметки O
данных O
MTS B-TERM
AI I-TERM
. O

# text =  Недавно рассказывал о том, как делать иерархически датасет из Википедии.
Недавно O
рассказывал O
о O
том O
, O
как O
делать O
иерархически O
датасет O
из O
Википедии B-TERM
. O

# text =  В этом посте хочу рассказать вам о Сноркеле - фреймворке для программирования данных (data programming).
В O
этом O
посте O
хочу O
рассказать O
вам O
о O
Сноркеле B-TERM
- O
фреймворке B-TERM
для I-TERM
программирования I-TERM
данных I-TERM
( O
data B-TERM
programming I-TERM
) O
. O


# text =  Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками. 

Проект O
стартовал O
в O
Стэнфорде B-TERM
как O
инструмент O
для O
помощи O
в O
разметке O
датасетов O
для O
задачи O
information B-TERM
extraction I-TERM
, O
а O
сейчас O
разработчики O
делают O
платформу O
для O
пользования O
внешними O
заказчиками O
. O


# text =  В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.
В O
разметочные B-TERM
функции I-TERM
( O
labeling B-TERM
functions I-TERM
) O
закодированы O
все O
возможные O
правила O
, O
по O
которым O
можно O
поставить O
какую O
- O
либо O
метку O
каждому O
примеру O
из O
набора O
данных O
. O

# text =  В качестве основы для таких функций используются:внешние базы данных, такие как WordNet или WikiBase.
В O
качестве O
основы O
для O
таких O
функций O
используются O
: O
внешние O
базы O
данных O
, O
такие O
как O
WordNet B-TERM
или O
WikiBase B-TERM
. O

# text =  Генеративная модель, являющаяся сердцем Сноркеля, попытается учесть недостатки отдельных функций.
Генеративная B-TERM
модель I-TERM
, O
являющаяся O
сердцем O
Сноркеля B-TERM
, O
попытается O
учесть O
недостатки O
отдельных O
функций O
. O

# text =  Для наглядности оставляю здесь иллюстрацию с последовательностью работы со Снокрелем для задачи information extraction из оригинальной статьи.
Для O
наглядности O
оставляю O
здесь O
иллюстрацию O
с O
последовательностью O
работы O
со O
Снокрелем B-TERM
для O
задачи O
information B-TERM
extraction I-TERM
из O
оригинальной O
статьи O
. O

# text =  Авторы оригинальной статьи представляют ее как факторный граф, или графическую вероятностную модель.
Авторы O
оригинальной O
статьи O
представляют O
ее O
как O
факторный B-TERM
граф I-TERM
, O
или O
графическую B-TERM
вероятностную I-TERM
модель I-TERM
. O

# text =  Тогда модель определяется так, чтобы обучить эту модель без доступа к истинным меткам, это нужно обучаться с помощью логарифмического негативного маргинализированного правдоподобия, зная матрицу Оптимизацию авторы проводили с помощью SGD с семплированием Гиббса.
Тогда O
модель O
определяется O
так
, O
чтобы O
обучить O
эту O
модель O
без O
доступа O
к O
истинным O
меткам O
, O
это O
нужно O
обучаться O
с O
помощью O
логарифмического B-TERM
негативного I-TERM
маргинализированного I-TERM
правдоподобия I-TERM
, O
зная O
матрицу B-TERM
Оптимизацию I-TERM
авторы O
проводили O
с O
помощью O
SGD B-TERM
с O
семплированием B-TERM
Гиббса I-TERM
. O

# text =  Загрузим заранее обученную модель fastText, чей выбор объясняется наличием огромного количества опечаток в текстах.
Загрузим O
заранее O
обученную O
модель O
fastText B-TERM
, O
чей O
выбор O
объясняется O
наличием O
огромного O
количества O
опечаток O
в O
текстах O
. O

# text =  Таким образом мы получили опорный вектор для класса "диарея".
Таким O
образом O
мы O
получили O
опорный B-TERM
вектор I-TERM
для O
класса O
" O
диарея O
" O
. O