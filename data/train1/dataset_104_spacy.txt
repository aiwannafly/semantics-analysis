# text =  Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.
Алгоритм O
понимания O
естественного O
языка O
( O
Natural B-TERM
Language I-TERM
Understanding I-TERM
, O
NLU B-TERM
) O
Microsoft B-TERM
DeBERTa B-TERM
превзошел O
человеческие O
возможности O
в O
одном O
из O
самых O
сложных O
тестов O
для O
подобных O
алгоритмов O
SuperGLUE B-TERM
. O

# text =  На данный момент модель занимает первое место в рейтинге с показателем в 90,3, в то время как среднее значение человеческих возможностей составляет 89,8 баллов.
На O
данный O
момент O
модель O
занимает O
первое O
место O
в O
рейтинге O
с O
показателем O
в O
90,3 B-TERM
, O
в O
то O
время O
как O
среднее O
значение O
человеческих O
возможностей O
составляет O
89,8 B-TERM
баллов O
. O

# text = Тест SuperGLUE включает в себя ряд задач, которые разработаны для оценки способности ИИ-моделей распознавать и понимать естественный язык, например, дать правильный ответ на вопрос на базе прочитанного абзаца, определить, правильно ли используется многозначное слово в определенном контексте и т.д.
Тест O
SuperGLUE B-TERM
включает O
в O
себя O
ряд O
задач O
, O
которые O
разработаны O
для O
оценки O
способности O
ИИ O
- O
моделей O
распознавать O
и O
понимать O
естественный O
язык O
, O
например O
, O
дать B-TERM
правильный I-TERM
ответ I-TERM
на I-TERM
вопрос I-TERM
на I-TERM
базе I-TERM
прочитанного I-TERM
абзаца I-TERM
, O
определить O
, O
правильно O
ли O
используется O
многозначное B-TERM
слово I-TERM
в O
определенном O
контексте O
и O
т.д. O

# text =  Тест был разработан группой исследователей в 2019 году.
Тест O
был O
разработан O
группой O
исследователей O
в O
2019 B-TERM
году O
. O

# text = Для того чтобы добиться текущего результата в 90,3 балла, DeBERTa получила масштабное обновление архитектуры: теперь она состоит из 48 слоев и имеет 1,5 млрд параметров.
Для O
того O
чтобы O
добиться O
текущего O
результата O
в O
90,3 B-TERM
балла O
, O
DeBERTa B-TERM
получила O
масштабное O
обновление O
архитектуры O
: O
теперь O
она O
состоит O
из O
48 B-TERM
слоев O
и O
имеет O
1,5 O
млрд O
параметров O
. O

# text =  Кроме того, DeBERTa будет интегрирована в следующую версию Тьюринговой модели Microsoft Turing (Turing NLRv4).
Кроме O
того O
, O
DeBERTa B-TERM
будет O
интегрирована O
в O
следующую O
версию O
Тьюринговой B-TERM
модели I-TERM
Microsoft I-TERM
Turing I-TERM
( O
Turing B-TERM
NLRv4 I-TERM
) O
. O

# text =  Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.
Тьюринговые B-TERM
модели I-TERM
используются O
в O
таких O
продуктах O
Microsoft B-TERM
, O
как O
Bing B-TERM
, O
Office B-TERM
, O
Dynamics B-TERM
и O
Azure B-TERM
Cognitive I-TERM
Services I-TERM
, O
чтобы O
совершенствовать O
, O
к O
примеру O
, O
взаимодействие O
с O
чат B-TERM
- I-TERM
ботами I-TERM
, O
предоставление O
рекомендаций O
и O
ответов O
на O
вопросы O
, O
поиск O
, O
автоматизацию 
поддержки O
клиентов O
, O
создание B-TERM
контента I-TERM
и O
решение O
многих O
других O
задач O
на O
пользу O
сотен O
миллионов O
пользователей O
. O

# text =  В отличии от машин, люди хорошо умеют использовать знания, ранее полученные при выполнении различных задач, для решения новых – это называется композиционным обобщением (англ. compositional generalization).
В O
отличии O
от O
машин O
, O
люди O
хорошо O
умеют O
использовать O
знания O
, O
ранее O
полученные O
при O
выполнении O
различных O
задач O
, O
для O
решения O
новых O
– O
это O
называется O
композиционным B-TERM
обобщением I-TERM
( O
англ O
. O
compositional B-TERM
generalization I-TERM
) O
. O
