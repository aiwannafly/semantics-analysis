# text =  Участникам предлагалось определить потенциальные заболевания коров по реальным жалобам людей из открытых источников, а также научиться выделять из текстов симптомы заболеваний (NER - Named Entity Recognition).
Участникам O
предлагалось O
определить O
потенциальные O
заболевания O
коров O
по O
реальным O
жалобам O
людей O
из O
открытых O
источников O
, O
а O
также O
научиться O
выделять O
из O
текстов O
симптомы O
заболеваний O
( O
NER B-TERM
- O
Named B-TERM
Entity I-TERM
Recognition I-TERM
) O
. O

# text =  Эта статья будет интересна не только тем, кто специализируется в NLP (Natural Language Processing), но и начинающим исследователям данных.
Эта O
статья O
будет O
интересна O
не O
только O
тем O
, O
кто O
специализируется O
в O
NLP B-TERM
( O
Natural B-TERM
Language I-TERM
Processing I-TERM
) O
, O
но O
и O
начинающим O
исследователям O
данных O
. O

# text =  Спаны - это участки текста, которые содержат в себе определенный смысл.
Спаны B-TERM
  O
- O
  O
это O
участки O
текста B-TERM
, O
которые O
содержат O
в O
себе O
определенный O
смысл O
. O

# text =  Программа для разметки YEDDA и процесс разметки.
Программа O
для O
разметки B-TERM
YEDDA B-TERM
и O
процесс O
разметки O
. O

# text =  Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.
Так O
как O
задача O
является O
составной O
, O
то O
и O
метрика O
состояла O
из O
двух O
компонентов O
с O
весом O
0.8 B-TERM
для O
задачи O
классификации B-TERM
и O
0.2 B-TERM
для O
задачи O
NER B-TERM
. O

# text =  В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.
В O
задаче O
классификации B-TERM
использовался O
logloss B-TERM
, O
вычисляемый O
как O
среднее O
значение O
метрики O
sklearn.metrics.log_loss B-TERM
по O
классам O
болезней O
. O

# text = В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.
В O
задаче O
NER B-TERM
использовался O
span B-TERM
- I-TERM
based I-TERM
F1-score I-TERM
, O
рассчитываемый O
следующим O
образом O
: O
для O
каждого O
текста B-TERM
берутся O
предсказанные O
индексы B-TERM
начала O
и O
конца O
размеченных O
признаков O
болезни O
, O
по O
ним O
выделяются O
из O
текста O
токены B-TERM
( O
отдельные O
слова B-TERM
, O
разделенные O
пробелом O
) O
и O
сравниваются O
с O
истинной O
( O
экспертной O
) O
разметкой B-TERM
. O

# text =  Код для подсчета метрики span-based F1-score.
Код O
для O
подсчета O
метрики O
span B-TERM
- I-TERM
based I-TERM
F1-score I-TERM
.

# text =  Этим решением стало использование классификатора CatBoost, который прямо из коробки может обрабатывать текстовые фичи.
Этим O
решением O
стало O
использование O
классификатора O
CatBoost B-TERM
, O
который O
прямо O
из O
коробки O
может O
обрабатывать O
текстовые O
фичи O
. O

# text =  Решение для задачи распознавания симптомов мы давать не стали, чтобы участники Data Science чемпионата могли покреативить.
Решение O
для O
задачи B-TERM
распознавания I-TERM
симптомов I-TERM
мы O
давать O
не O
стали O
, O
чтобы O
участники O
Data B-TERM
Science I-TERM
чемпионата O
могли O
покреативить O
. O

# text =  Во-первых, конкретно для этого соревнования наиболее эффективный подход - это доразметка спанов тренировочных данных для задачи NER.
Во O
- O
первых O
, O
конкретно O
для O
этого O
соревнования O
наиболее O
эффективный O
подход O
- O
это O
доразметка B-TERM
спанов I-TERM
тренировочных I-TERM
данных I-TERM
для O
задачи O
NER B-TERM
. O

# text =  Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.
Во O
- O
вторых O
, O
участники O
использовали O
базовые O
подходы O
для O
NLP B-TERM
- O
задач O
: O
удаление O
стоп O
- O
слов O
и O
знаков O
пунктуации O
, O
приведение O
к O
нижнему O
регистру O
, O
стемминг B-TERM
и O
лемматизация B-TERM
. O

# text = Более же продвинутым подходом является аугментация данных.
Более O
же O
продвинутым O
подходом O
является O
аугментация B-TERM
данных I-TERM
. O

# text =  Один из возможных способов аугментации текста - перифраз текста.
Один O
из O
возможных O
способов O
аугментации B-TERM
текста I-TERM
- O
перифраз B-TERM
текста I-TERM
. O

# text =  Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.
Примером O
данного O
решения O
является O
использование O
парафрайзера B-TERM
на O
основе O
“ O
rut5-base B-TERM
- I-TERM
paraphraser I-TERM
” O
из O
библиотеки O
huggingface B-TERM
. O

# text =  Реализуется данный метод аналогично с предыдущим, как модель можно использовать “LaBSE-en-ru”.
Реализуется O
данный O
метод O
аналогично O
с O
предыдущим O
, O
как O
модель O
можно O
использовать O
“ O
LaBSE B-TERM
- I-TERM
en I-TERM
- I-TERM
ru I-TERM
” O
. O

# text =  Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.
Сначала O
решается O
задача B-TERM
выделения I-TERM
симптомов I-TERM
( O
NER B-TERM
) O
, O
после O
чего O
в O
текстах B-TERM
убираются O
все O
слова B-TERM
, O
не O
являющиеся O
симптомами O
. O

# text =  Базовым вариантом эмбеддингов является TF-IDF, который зависит от частоты употребления слова в документе.
Базовым O
вариантом O
эмбеддингов B-TERM
является O
TF B-TERM
- I-TERM
IDF I-TERM
, O
который O
зависит O
от O
частоты B-TERM
употребления I-TERM
слова I-TERM
в O
документе O
. O

# text =  И чтобы его улучшить, можно использовать эмбеддинги предобученных моделей, таких как Word2Vec, FastText и тд.
И O
чтобы O
его O
улучшить O
, O
можно O
использовать O
эмбеддинги B-TERM
предобученных I-TERM
моделей I-TERM
, O
таких O
как O
Word2Vec B-TERM
, O
FastText B-TERM
и O
тд O
. O

# text =  В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.
В O
частности O
, O
в O
одном O
из O
лучших O
решений O
использовался O
необычный O
FastText B-TERM
, O
предобученный O
на O
корпусе O
текстов O
RuDReC B-TERM
, O
который O
содержит O
отзывы O
потребителей O
на O
русском B-TERM
языке I-TERM
о O
фармацевтической O
продукции O
. O

# text =  Напомним, что алгоритм работы с трансформерами можно представить следующим образом: сначала тексты преобразовываются токенизатором, далее обучается модель-трансформер.
Напомним O
, O
что O
алгоритм O
работы O
с O
трансформерами B-TERM
можно O
представить O
следующим O
образом O
: O
сначала O
тексты O
преобразовываются O
токенизатором B-TERM
, O
далее O
обучается O
модель B-TERM
- I-TERM
трансформер I-TERM
. O

# text =  Если же говорить о выборе моделей, то наилучшие результаты были получены следующими из них: RuBERT-base, RuBERT-large, LaBSE-en-ru.
Если O
же O
говорить O
о O
выборе O
моделей O
, O
то O
наилучшие O
результаты O
были O
получены O
следующими O
из O
них O
: O
RuBERT B-TERM
- I-TERM
base I-TERM
, O
RuBERT B-TERM
- I-TERM
large I-TERM
, O
LaBSE B-TERM
- I-TERM
en I-TERM
- I-TERM
ru I-TERM
. O

# text =  Предположим, что вы и так слышали о моделях семейства BERT (в предыдущей статье мы описывали, как применяем BERT в других задачах), а вот LaBSE - выбор совершенно неочевидный.
Предположим O
, O
что O
вы O
и O
так O
слышали O
о O
моделях O
семейства O
BERT B-TERM
( O
в O
предыдущей O
статье O
мы O
описывали O
, O
как O
применяем O
BERT B-TERM
в O
других O
задачах O
) O
, O
а O
вот O
LaBSE B-TERM
- O
выбор O
совершенно O
неочевидный O
. O

# text = Далее слова в тестовом наборе текстов также приводятся к векторам и сравниваются со словами из тренировочной разметки при помощи косинусной близости.
Далее O
слова O
в O
тестовом O
наборе O
текстов O
также O
приводятся O
к O
векторам O
и O
сравниваются O
со O
словами O
из O
тренировочной O
разметки O
при O
помощи O
косинусной B-TERM
близости I-TERM
. O

# text =  Архитектура в свою очередь может содержать LSTM, BiLSTM, RNN или GRU слои.
Архитектура O
в O
свою O
очередь O
может O
содержать O
LSTM B-TERM
, O
BiLSTM B-TERM
, O
RNN B-TERM
или O
GRU B-TERM
слои O
. O

# text =  Из интересных решений один из участников представил BiLSTM-сеть с CRF слоем.
Из O
интересных O
решений O
один O
из O
участников O
представил O
BiLSTM B-TERM
- I-TERM
сеть I-TERM
с O
CRF B-TERM
слоем O
. O

# text =  Используются те же модели, поэтому расскажем о различии в подготовке данных для моделей.Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.
Используются O
те O
же O
модели O
, O
поэтому O
расскажем O
о O
различии O
в O
подготовке O
данных O
для O
моделей O
. O
Для O
задачи O
NER B-TERM
тексты O
преобразовываются O
с O
помощью O
токенизатора B-TERM
и O
теггинга B-TERM
. O

# text =  Сначала тексты при помощи токенизатора переводятся в вектора - это то, на чем обучается модель.
Сначала O
тексты O
при O
помощи O
токенизатора B-TERM
переводятся O
в O
вектора B-TERM
- O
это O
то O
, O
на O
чем O
обучается O
модель O
. O

# text =  Далее создаются таргеты при помощи теггинга.
Далее O
создаются O
таргеты B-TERM
при O
помощи O
теггинга B-TERM
. O

# text =  Самым распространенным алгоритмом теггинга является “Inside–outside–beginning”.
Самым O
распространенным O
алгоритмом O
теггинга O
является O
“ O
Inside B-TERM
– I-TERM
outside I-TERM
– I-TERM
beginning I-TERM
” 
. O

# text =  Тег указывает на то, что слово находится внутри спана.
Тег B-TERM
указывает O
на O
то O
, O
что O
слово O
находится O
внутри O
спана B-TERM
. O

# text =  Среди решений были как кастомный код для обучения и инференса, так и код от huggingface, который можно использовать из коробки.
Среди O
решений O
были O
как O
кастомный O
код O
для O
обучения O
и O
инференса O
, O
так O
и O
код O
от O
huggingface B-TERM
, O
который O
можно O
использовать O
из O
коробки O
. O

# text =  Безусловно, основной метрикой оценивания являлся лидерборд.
Безусловно O
, O
основной O
метрикой O
оценивания O
являлся O
лидерборд B-TERM
. O
