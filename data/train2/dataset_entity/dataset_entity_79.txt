# text =   Энкодер предложений (sentence encoder) – это модель, которая сопоставляет коротким текстам векторы в многомерном пространстве, причём так, что у текстов, похожих по смыслу, и векторы тоже похожи.
Энкодер B-Method
предложений I-Method
( O
sentence B-Method
encoder I-Method
) O
– O
это O
модель O
, O
которая O
сопоставляет O
коротким O
текстам O
векторы O
в O
многомерном O
пространстве O
, O
причём O
так O
, O
что O
у O
текстов O
, O
похожих O
по O
смыслу O
, O
и O
векторы O
тоже O
похожи O
. O

# text =   Обычно для этой цели используются нейросети, а полученные векторы называются эмбеддингами.
Обычно O
для O
этой O
цели O
используются O
нейросети B-Method
, O
а O
полученные O
векторы O
называются O
эмбеддингами B-Object
. O

# text =   Они полезны для кучи задач, например, few-shot классификации текстов, семантического поиска, или оценки качества перефразирования.
Они O
полезны O
для O
кучи O
задач O
, O
например O
, O
few B-Task
- I-Task
shot I-Task
классификации I-Task
текстов B-Task
, O
семантического B-Task
поиска I-Task
, O
или O
оценки B-Task
качества I-Task
перефразирования I-Task
. O

# text =   Самой качественной моделью оказался mUSE, самой быстрой из предобученных – FastText, а по балансу скорости и качества победил rubert-tiny2.
Самой O
качественной O
моделью O
оказался O
mUSE B-Model
, O
самой O
быстрой O
из O
предобученных O
– O
FastText B-Model
, O
а O
по O
балансу O
скорости O
и O
качества O
победил O
rubert B-Model
- I-Model
tiny2 I-Model
. O

# text =   Первой известной попыткой системно сравнить английские эмбеддинги предложений был SentEval, сочетающий чисто лингвистические задачи со вполне прикладными.
Первой O
известной O
попыткой O
системно O
сравнить O
английские O
эмбеддинги B-Object
предложений O
был O
SentEval B-Dataset
, O
сочетающий O
чисто O
лингвистические O
задачи O
со O
вполне O
прикладными O
. O

# text =   Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк "сложных" NLP задач; фокус на дообучаемых моделях.
Для O
русского B-Lang
языка O
тоже O
было O
создано O
немало O
разного O
рода O
бенчмарков O
NLU ShortName
моделей O
: O
RussianSuperGLUE B-Model
: O
бенчмарк O
" O
сложных O
" O
NLP B-Task
задач I-Task
; O
фокус O
на O
дообучаемых O
моделях O
. O

# text = MOROCCO: RussianSuperGLUE + оценка производительности, довольно трудновоспроизводимый бенчмарк.
MOROCCO O
: O
RussianSuperGLUE B-Model
+ O
оценка O
производительности O
, O
довольно O
трудновоспроизводимый O
бенчмарк O
. O

# text =   RuSentEval: бенчмарк BERT-подобных энкодеров предложений на лингвистических задачах.
RuSentEval B-Application
: O
бенчмарк O
BERT B-Model
- I-Model
подобных I-Model
энкодеров I-Model
предложений I-Model
на O
лингвистических O
задачах O
. O

# text =   SentEvalRu и deepPavlovEval: два хороших, но давно не обновлявшихся прикладных бенчмарка.
SentEvalRu B-Application
и O
deepPavlovEval B-Application
: O
два O
хороших O
, O
но O
давно O
не O
обновлявшихся O
прикладных O
бенчмарка O
. O

# text =   С тех пор появилось много новых русскоязычных моделей, включая rubert-tiny2, поэтому и бенчмарк пришло время обновить.
С O
тех O
пор O
появилось O
много O
новых O
русскоязычных O
моделей O
, O
включая O
rubert B-Model
- I-Model
tiny2 I-Model
, O
поэтому O
и O
бенчмарк O
пришло O
время O
обновить O
. O

# text =   В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.
В O
основу O
бенчмарка O
легли O
BERT B-Model
- I-Model
подобные I-Model
модели I-Model
: O
sbert_large_nlu_ru B-Model
, O
sbert_large_mt_nlu_ru B-Model
, O
и O
ruRoberta B-Model
- I-Model
large I-Model
от O
Сбера B-Organization
; O
rubert B-Model
- I-Model
base I-Model
- I-Model
cased I-Model
- I-Model
sentence I-Model
, O
rubert B-Model
- I-Model
base I-Model
- I-Model
cased I-Model
- I-Model
conversational I-Model
, O
distilrubert B-Model
- I-Model
tiny I-Model
- I-Model
cased I-Model
- I-Model
conversational I-Model
, O
и O
distilrubert B-Model
- I-Model
base I-Model
- I-Model
cased I-Model
- I-Model
conversational I-Model
от O
DeepPavlov B-Organization
; O
мои O
rubert B-Model
- I-Model
tiny I-Model
и O
rubert B-Model
- I-Model
tiny2 I-Model
; O
мультиязычные O
LaBSE B-Model
( O
плюс O
урезанная O
версия O
LaBSE B-Model
- I-Model
en I-Model
- I-Model
ru I-Model
) O
и O
старый O
добрый O
bert B-Model
- I-Model
base I-Model
- I-Model
multilingual I-Model
- I-Model
cased I-Model
. O

# text =   Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.
Кроме O
этого O
, O
я O
добавил O
в O
бенчмарк O
разные O
T5 B-Model
модели I-Model
, O
т.к. O
они O
тоже O
должны O
хорошо O
понимать O
тексты O
: O
мои O
rut5-small B-Model
, O
rut5-base B-Model
, O
rut5-base B-Model
- I-Model
multitask I-Model
, O
и O
rut5-base B-Model
- I-Model
paraphraser I-Model
, O
и O
Сберовские B-Organization
ruT5-base B-Model
и O
ruT5-large B-Model
. O

# text =   Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.
Помимо O
BERTов O
и O
T5 O
, O
я O
включил O
в O
бенчмарк O
большие O
мультиязычные O
модели O
Laser B-Model
от O
FAIR B-Model
и O
USE B-Model
- I-Model
multilingual I-Model
- I-Model
large I-Model
от O
Google B-Organization
. O

# text =   В качестве быстрого бейзлайна, я добавил FastText, а именно, geowac_tokens_none_fasttextskipgram_300_5_2020  с RusVectores, а также его сжатую версию.
В O
качестве O
быстрого O
бейзлайна O
, O
я O
добавил O
FastText B-Model
, O
а O
именно O
, O
geowac_tokens_none_fasttextskipgram_300_5_2020 B-Model
с O
RusVectores B-Model
, O
а O
также O
его O
сжатую O
версию O
. O

# text =   Наконец, я добавил парочку "моделей", которые вообще не выучивают никаких параметров, а просто используют HashingVectorizer для превращения текста в вектор признаков.
Наконец O
, O
я O
добавил O
парочку O
" O
моделей O
" O
, O
которые O
вообще O
не O
выучивают O
никаких O
параметров O
, O
а O
просто O
используют O
HashingVectorizer B-Application
для O
превращения O
текста O
в O
вектор O
признаков O
. O

# text =   Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.
Это O
доработанная O
версия O
rubert B-Model
- I-Model
tiny I-Model
: O
я O
расширил O
словарь O
модели O
c O
30К O
до O
80К O
токенов O
, O
увеличил O
максимальную O
длину O
текста O
с O
512 O
до O
2048 O
токенов O
, O
и O
дообучил O
модель O
на O
комбинации O
задач O
masked B-Task
language I-Task
modelling I-Task
, O
natural B-Task
language I-Task
inference I-Task
, O
и O
аппроксимации B-Task
эмбеддингов I-Task
LaBSE I-Task
. O

# text =   В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.
В O
новой O
версии O
бенчмарка O
я O
оставил O
всё O
те O
же O
10 O
задач O
, O
что O
и O
в O
прежней O
, O
но O
слегка O
изменил O
формат O
некоторых O
из O
них O
: O
Semantic B-Task
text I-Task
similarity I-Task
( O
STS B-ShortName
) O
на O
основе O
переведённого O
датасета O
STS B-Dataset
- I-Dataset
B I-Dataset
; O
Paraphrase B-Task
identification I-Task
( O
PI B-ShortName
) O
на O
основе O
датасета O
paraphraser.ru B-Dataset
; O
Natural B-Task
language I-Task
inference I-Task
( O
NLI B-ShortName
) O
на O
датасете O
XNLI B-Dataset
; O
Sentiment B-Task
analysis I-Task
( O
SA B-ShortName
) O
на O
данных O
SentiRuEval2016 B-Dataset
. O

# text =   В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.
В O
прошлой O
версии O
бенчмарка O
я O
собрал O
кривые O
тестовые O
выборки O
, O
поэтому O
этот O
датасет O
я O
переделал O
; O
Toxicity B-Task
identification I-Task
( O
TI B-ShortName
) O
на O
датасете B-Dataset
токсичных I-Dataset
комментариев I-Dataset
из O
OKMLCup B-Application
; O
Inappropriateness B-Task
identification I-Task
( O
II B-ShortName
) O
на O
датасете B-Dataset
Сколтеха I-Dataset
; O
Intent B-Task
classification I-Task
( O
IC B-ShortName
) O
и O
её O
кросс O
- O
язычная O
версия O
ICX B-ShortName
на O
датасете O
NLU B-Dataset
- I-Dataset
evaluation I-Dataset
- I-Dataset
data I-Dataset
, O
который O
я O
автоматически O
перевёл O
на O
русский B-Lang
. O

# text =   В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.
В O
IC B-Model
классификатор I-Model
обучается O
на O
русских B-Lang
данных O
, O
а O
в O
ICX B-Model
– O
на O
английских B-Lang
, O
а O
тестируется O
в O
обоих O
случаях O
на O
русских O
. O

# text =   Распознавание именованных сущностей () на датасетах factRuEval-2016E1) и RuDReC (NE2).
Распознавание B-Task
именованных I-Task
сущностей I-Task
( O
) O
на O
датасетах O
factRuEval-2016E1 B-Dataset
) O
и O
RuDReC B-Dataset
( O
NE2 B-Dataset
) O
. O

# text =   Эти две задачи требуют получать эмбеддинги отдельных токенов, а не целых предложений; поэтому модели USE и Laser, не выдающие эмбеддинги токенов "из коробки", в оценке этих задач не участвовали.
Эти O
две O
задачи O
требуют O
получать O
эмбеддинги O
отдельных O
токенов O
, O
а O
не O
целых O
предложений O
; O
поэтому O
модели O
USE B-Model
и O
Laser B-Model
, O
не O
выдающие O
эмбеддинги O
токенов O
" O
из O
коробки O
" O
, O
в O
оценке O
этих O
задач O
не O
участвовали O
. O

# text =   В задачах STS, PI и NLI оценивается степень связи двух текстов.
В O
задачах O
STS B-Task
, O
PI B-Task
и O
NLI B-Task
оценивается O
степень O
связи O
двух O
текстов O
. O

# text =   Хороший энкодер предложений должен отражать эту степень в их косинусной близости, поэтому для STS и PI мы измеряем качество как Спирмановскую корреляцию косинусной близости и человеческих оценок сходства.
Хороший O
энкодер O
предложений O
должен O
отражать O
эту O
степень O
в O
их O
косинусной B-Metric
близости B-Metric
, O
поэтому O
для O
STS B-Task
и O
PI B-Task
мы O
измеряем O
качество O
как O
Спирмановскую B-Metric
корреляцию I-Metric
косинусной O
близости O
и O
человеческих O
оценок O
сходства O
. O

# text =   Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).
Для O
NLI B-Abbrev_Task
я O
обучил O
трёхклассовую O
( O
entail O
/ O
contradict O
/ O
neutral O
) O
логистическую B-Model
регрессию I-Model
поверх O
косинусной B-Metric
близости I-Metric
, O
и O
измеряю O
её O
точность B-Metric
( O
accuracy B-Metric
) O
. O

# text =   Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).
Для O
задач O
бинарной O
классификации O
TI B-Abbrev_Task
и O
II B-Abbrev_Task
я O
измеряю O
ROC B-Metric
AUC I-Metric
, O
а O
в O
задачах O
многоклассовой O
классификации O
SA B-Abbrev_Task
, O
IC B-Abbrev_Task
и O
ICX B-Abbrev_Task
– O
точность B-Metric
( O
accuracy B-Metric
) O
. O

# text =   Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.
Для O
всех O
задач O
классификации B-Task
я O
обучаю O
логистическую B-Model
регрессию I-Model
либо O
KNN B-ShortName_Method
поверх O
эмбеддингов O
предложений B-Subject
, O
и O
выбираю O
лучшую O
модель B-Object
из O
двух O
. O

# text =   Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О. 
Для O
задач O
NER B-Abbrev_Task
я O
классифицировал O
токены O
логистической B-Method
регрессией I-Method
поверх O
их O
эмбеддингов O
, O
и O
измерял O
macro B-Metric
F1 I-Metric
по O
всем O
классам O
токенов O
, O
кроме O
О O

# text =  Поскольку разные модели токенизируют тексты по-разному, я токенизировал все тексты razdel'ом, и вычислял эмбеддинг слова как средний эмбеддинг его токенов.
Поскольку O
разные O
модели O
токенизируют O
тексты O
по O
- O
разному O
, O
я O
токенизировал O
все O
тексты O
razdel'ом B-Technology
, O
и O
вычислял O
эмбеддинг O
слова O
как O
средний O
эмбеддинг O
его O
токенов O
. O

# text =   Единого победителя нет, но MUSE, sbert_large_mt_nlu_ru и rubert-base-cased-sentence взяли по многу призовых мест.
Единого O
победителя O
нет O
, O
но O
MUSE B-Model
, O
sbert_large_mt_nlu_ru B-Model
и O
rubert B-Model
- I-Model
base I-Model
- I-Model
cased I-Model
- I-Model
sentence I-Model
взяли O
по O
многу O
призовых O
мест O
. O

# text =   Удивительно, но модели T5 очень хорошо показали себя на задачах NER.
Удивительно O
, O
но O
модели O
T5 B-Model
очень O
хорошо O
показали O
себя O
на O
задачах O
NER B-Abbrev_Task
. O

# text =   Самыми качественными энкодерами предложений оказались мультиязычные MUSE, LaBSE и Laser.
Самыми O
качественными O
энкодерами O
предложений O
оказались O
мультиязычные O
MUSE B-Model
, O
LaBSE B-Model
и O
Laser B-Model
. O

# text =   Но выбирать стоит из Парето-оптимальных моделей: таких, что ни одна другая модель не превосходит их по всем критериям.
Но O
выбирать O
стоит O
из O
Парето B-Object
- I-Object
оптимальных I-Object
моделей I-Object
: O
таких O
, O
что O
ни O
одна O
другая O
модель O
не O
превосходит O
их O
по O
всем O
критериям O
. O

# text =   Из 25 моделей только 12 Парето-оптимальны:MUSE, rubert-tiny2, FT_geowac, Hashing_1000_char и Hashing_1000 обладают самым лучшим качеством для своей скорости на CPU; MUSE, LaBSE, rubert-tiny2, и distilbert-tiny обладают наилучшим качеством для своей скорости на GPU;MUSE, LaBSE, rubert-tiny2, rubert-tiny, FT_geowac_21mb, и Hashing_1000_char обладают наилучшим качеством для своего размера.
Из O
25 O
моделей O
только O
12 O
Парето O
- O
оптимальны O
: O
MUSE B-Model
, O
rubert B-Model
- I-Model
tiny2 I-Model
, O
FT_geowac B-Model
, O
Hashing_1000_char B-Model
и O
Hashing_1000 B-Model
обладают O
самым O
лучшим O
качеством O
для O
своей O
скорости O
на O
CPU O
; O
MUSE B-Model
, O
LaBSE B-Model
, O
rubert B-Model
- I-Model
tiny2 I-Model
, O
и O
distilbert B-Model
- I-Model
tiny I-Model
обладают O
наилучшим O
качеством O
для O
своей O
скорости O
на O
GPU O
; O
MUSE B-Model
, O
LaBSE B-Model
, O
rubert B-Model
- I-Model
tiny2 I-Model
, O
rubert B-Model
- I-Model
tiny I-Model
, O
FT_geowac_21 B-Model
mb O
, O
и O
Hashing_1000_char B-Model
обладают O
наилучшим O
качеством O
для O
своего O
размера O
. O

# text =   Актуальный лидерборд смотрите в репозитории: https://github.com/avidale/encodechka
Актуальный O
лидерборд O
смотрите O
в O
репозитории O
: O
https://github.com/avidale/encodechka B-URL_InfoResource
. O
