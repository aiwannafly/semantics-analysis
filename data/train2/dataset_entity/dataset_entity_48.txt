# text =  Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.
Наше O
выработанное O
решение O
– O
обучить O
нейронную B-Method
сеть I-Method
, O
которая O
способна O
по O
тексту O
обращения O
автоматически B-Task
распознавать I-Task
заранее I-Task
ранжированные I-Task
по I-Task
классам I-Task
проблемы I-Task
, O
извлекать O
сущность O
( O
номер O
заказа O
и O
телефон O
клиента O
) O
и O
по O
определённым O
классам O
сделать O
автоматизацию O
решения O
. O

# text =   На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).
На O
самом O
деле O
уже O
существуют O
продвинутые O
и O
проверенные O
методы O
ее O
обработки O
, O
использующие O
нейронные B-Method
сети I-Method
, O
с O
распознаванием O
смысла O
и O
контекста O
– O
BERT B-ShortName
( O
Bidirectional B-Method
Encoder I-Method
Representations I-Method
from I-Method
Transformers I-Method
) O
. O

# text =   Перед тем как выбрать нейронные сети, мы протестировали несколько более стандартных архитектур, случайные леса и бустинг.
Архитектура O
модели B-Object
Перед O
тем O
как O
выбрать O
нейронные B-Method
сети I-Method
, O
мы O
протестировали O
несколько O
более O
стандартных O
архитектур O
, O
случайные B-Method
леса I-Method
и O
бустинг B-Method
. O

# text =   Эта модель была обучена на огромном корпусе русскоязычного текста с двумя задачами – предсказать замаскированное слово в предложениях и предсказать, если одно из предложений следует по смыслу за вторым.
Эта O
модель O
была O
обучена O
на O
огромном O
корпусе O
русскоязычного O
текста O
с O
двумя O
задачами O
– O
предсказать B-Task
замаскированное I-Task
слово I-Task
в I-Task
предложениях I-Task
и O
предсказать O
, O
если O
одно O
из O
предложений O
следует O
по O
смыслу O
за O
вторым O
. O

# text =   Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).
Наша O
задача O
– O
дообучить O
эту O
языковую O
модель O
для O
нашего O
приложения O
( O
одна O
модель B-Object
для O
классификации B-Task
и O
одна O
– O
для O
извлечения B-Task
сущности I-Task
) O
. O

# text =   результат первой модели – точность 77%
результат O
первой O
модели O
– O
точность B-Metric
77% B-Value

# text =   Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).
Чтобы O
определить O
, O
какие O
ещё O
есть O
потенциальные O
классы O
, O
мы O
повели O
так O
называемое O
тематическое B-Method
моделирование I-Method
, O
используя O
несколько O
подходов O
: O
начиная O
от O
пробалистических B-Model
моделей B-Model
( O
латентное B-Method
распределение I-Method
Дирихле I-Method
, O
ARTM B-ShortName
) O
и O
всё O
те O
же O
нейронные B-Method
сети I-Method
( O
BERT B-Model
) O
. O

# text =   Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.
Теперь O
нам O
нужно O
было O
использовать O
некоторые O
технические O
способы O
, O
чтобы O
сделать O
максимально O
высоким O
качество O
модели O
, O
которая O
на O
новых O
классах O
давала O
точность B-Metric
72 B-Value
% I-Value
. O

# text =   Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.
Второе O
, O
мы O
стандартно O
провели O
экстенсивный B-Method
тюнинг I-Method
гиперпараметров I-Method
и O
изменили O
нашу O
метрику O
с O
точности B-Metric
на O
F1 B-Metric
, O
чтобы O
ставить O
больше O
акцента O
на O
точность B-Metric
по O
каждому O
классу O
, O
так O
как O
общая O
точность B-Metric
предвзято O
относится O
к O
доминирующим O
классам O
. O

# text =   Изменение оптимизирующей метрики на F1 позволило алгоритму обучения дольше обучаться, так как почти на каждом этапе происходило улучшение по F1, когда метрика была точность, мы достигали плато гораздо быстрее.
Изменение O
оптимизирующей O
метрики O
на O
F1 B-Metric
позволило O
алгоритму O
обучения O
дольше O
обучаться O
, O
так O
как O
почти O
на O
каждом O
этапе O
происходило O
улучшение O
по O
F1 B-Metric
, O
когда O
метрика O
была O
точность B-Metric
, O
мы O
достигали O
плато O
гораздо O
быстрее O
. O

# text =   Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.
Изначально O
на O
этапе O
MVP B-ShortName
( O
minimum B-Object
viable I-Object
product I-Object
) O
мы O
применяли O
регулярные B-Object
выражения I-Object
для O
извлечения B-Task
сущности I-Task
. O

# text =   Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.
Протестировав O
поведение O
модели O
на O
продовских O
данных O
, O
мы O
обнаружили O
, O
что O
точность B-Metric
извлечения O
была O
около O
50 B-Value
% I-Value
. O

# text =   Мы поняли, что даже извлечение сущности зависит от контекста, и решили использовать BERT.
Мы O
поняли O
, O
что O
даже O
извлечение B-Task
сущности I-Task
зависит O
от O
контекста O
, O
и O
решили O
использовать O
BERT B-Model
. O

# text =   На вход необходимо представить размеченные данные с маркировкой BIO (beginning, intermediate, O – пустота).
На O
вход O
необходимо O
представить O
размеченные O
данные O
с O
маркировкой B-Object
BIO B-ShortName
( O
beginning O
, O
intermediate O
, O
O O
– O
пустота O
) O
. O

# text =   Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.
Мы O
производили O
разметку B-Method
800 O
обращений O
на O
DataTurcks B-Dataset
: O
Точность B-Metric
подхода O
BERT O
– O
94 B-Value
% I-Value
на O
этапе O
обучения O
, O
она O
валидирована O
на O
тестовых O
данных O
. O

# text =   Это постобработка увеличила точность до 98%.
Это O
постобработка O
увеличила O
точность B-Metric
до O
98% B-Value

# text =   В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.
В O
иностранной O
литературе O
можно O
встретить O
термин O
Continuous B-Method
Learning I-Method
( O
CL B-ShortName
) O
, O
который O
объединяет O
различные O
методы O
использования O
новых O
данных O
для O
поддержания O
эффективности O
моделей O
. O

# text =   Методы CL были положены в основу пайплайна переобучения.
Методы O
CL B-ShortName
были O
положены O
в O
основу O
пайплайна O
переобучения O
. O
