# text =   Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.
Некоторое O
время O
назад O
к O
нам O
обратился O
заказчик O
с O
не O
совсем O
обычной O
задачей O
— O
воспроизвести O
сервис O
IBM B-Technology
Watson I-Technology
Personality I-Technology
Insights I-Technology
, O
который O
анализировал B-Task
текст I-Task
, O
написанный O
человеком O
и O
определял O
по O
нему O
ряд O
личностных B-Object
характеристик I-Object
. O

# text =   Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.
Основная O
идея O
данного O
сервиса O
состояла O
в O
том O
, O
что O
он O
получает O
на O
вход O
текст O
написанный O
определенным O
человеком O
и O
определяет B-Task
по O
этому O
тексту O
четыре O
группы I-Task
характеристик I-Task
личности I-Task
. O

# text =   Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.
Например O
, O
Personality B-Technology
Insights I-Technology
использовался O
в O
психотерапии B-Science
для O
оценки B-Task
состояния I-Task
пациентов I-Task
[ O
5 O
] O
, O
в O
искусстве O
( O
оценка B-Task
личности I-Task
персонажей I-Task
пьес I-Task
Шекспира I-Task
) O
[ O
6 O
] O
, O
определении B-Task
спама I-Task
[ O
7 O
] O
а O
также O
в O
научных O
исследованиях O
. O

# text =   На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.
На O
сайте O
Personality B-Technology
Insights I-Technology
качество O
моделейO
Watson B-Technology
оценивалось O
с O
помощью O
двух O
показателей O
— O
средней B-Metric
абсолютной I-Metric
ошибки I-Metric
( O
MAE B-ShortName_Metric
) O
и O
коэффициента B-Metric
корреляции I-Metric
. O

# text =   В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].
В O
литературе O
для O
предсказания O
характеристик O
Big O
5 O
использовались O
различные O
методы O
линейная B-Method
регрессия I-Method
с O
использованием O
признаков O
полученных O
латентным O
семантическим O
анализом O
[ O
11 O
] O
, O
ридж B-Method
- I-Method
регрессия I-Method
по O
большому O
набору O
собранных O
вручную O
признаков O
[ O
12 O
] O
, O
SVM B-ShortName_Method
с O
признаками O
TF B-Metric
/ O
IDF B-Metric
[ O
13 O
] O
, O
word2vec B-Model
и O
doc2vec B-Model
[ O
14 O
] O
. O

# text =   В более современных работах присутствуют сверточные нейронные сети [15, 16], а также предобученные модели BERT [17]
В O
более O
современных O
работах O
присутствуют O
сверточные B-Method
нейронные B-Method
сети I-Method
[ O
15 O
, O
16 O
] O
, O
а O
также O
предобученные O
модели O
BERT B-Model
[ O
17 O
] O

# text =  Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).
Модель O
, O
которую O
построил O
заказчик O
использовала O
вектора O
слов O
word2vec B-Model
и O
рекуррентную O
нейронную O
сеть O
на O
базе O
GRU B-ShortName_Method
( O
gated B-Method
recurrent I-Method
unit I-Method
) O
( O
Рис O
1а O
) O
. O

# text =   Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).
Обучалась O
модель B-Object
с O
функцией O
ошибки O
MSE B-ShortName_Method
( O
среднеквадратичное B-Method
отклонение I-Method
) O
. O

# text =   Сигмоидная функция активации обычно не очень хорошо подходит для задачи регрессии.
Сигмоидная B-Method
функция I-Method
активации I-Method
обычно O
не O
очень O
хорошо O
подходит O
для O
задачи O
регрессии B-Task
. O

# text =   В литературе для регрессии рекомендуют использовать линейную активацию или RelU.
В O
литературе O
для O
регрессии B-Task
рекомендуют O
использовать O
линейную B-Method
активацию I-Method
или O
RelU B-Method
. O

# text =   Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.
Вычислив O
MAE B-Metric
отдельно O
для O
характеристики O
личности O
и O
отдельно O
для O
потребительских O
предпочтений O
получили O
значения O
0.11 B-Value
и O
0.148 B-Value
соответственно O
, O
т O
. O
  O
е O
. O
потребительские O
предпочтения O
сильно O
портят O
общую O
картину O
. O

# text =   Замена BERT на более современную модель XLM RoBERTa large позволило улучшить результаты (эта модель более ресурсозатратная и медленная, но заказчик сказал, что скорость работы не критична).
Замена O
BERT O
на O
более O
современную O
модель O
XLM B-Model
RoBERTa I-Model
large I-Model
позволило O
улучшить O
результаты O
( O
эта O
модель O
более O
ресурсозатратная O
и O
медленная O
, O
но O
заказчик O
сказал O
, O
что O
скорость O
работы O
не O
критична O
) O
. O

# text =   Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.
Итоговый O
MAE B-Metric
составил O
0.073 B-Value
для O
характеристик O
личности O
и O
0.098 B-Value
для O
потребительских O
предпочтений O
. O

# text =   Получились немного разные цифры, но средний коэффициент корреляции по всем параметрам составил 0.68, что говорит о том, что характеристики, выдаваемые с разных переводов одного текста должны быть весьма похожи.
Получились O
немного O
разные O
цифры O
, O
но O
средний O
коэффициент B-Metric
корреляции I-Metric
по O
всем O
параметрам O
составил O
0.68 B-Value
, O
что O
говорит O
о O
том O
, O
что O
характеристики O
, O
выдаваемые O
с O
разных O
переводов O
одного O
текста O
должны O
быть O
весьма O
похожи O
. O

# text =   Надо сказать, что признаки, формируемые верхними слоями подобных моделей не всегда являются самыми лучшими, точнее даже сказать, как правило, не являются — в классических задачах, таких как поиск именованных сущностей или ответы на вопросы по тексту, признаки верхних уровней работают хуже, чем признаки промежуточных [18].
Надо O
сказать O
, O
что O
признаки O
, O
формируемые O
верхними O
слоями O
подобных O
моделей O
не O
всегда O
являются O
самыми O
лучшими O
, O
точнее O
даже O
сказать O
, O
как O
правило O
, O
не O
являются O
— O
в O
классических O
задачах O
, O
таких O
как O
поиск B-Task
именованных I-Task
сущностей I-Task
или O
ответы O
на O
вопросы O
по O
тексту O
, O
признаки O
верхних O
уровней O
работают O
хуже O
, O
чем O
признаки O
промежуточных O
[ O
18 O
] O
. O
