# text =   Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.
Известный O
учёный O
Алан B-Person
Тьюринг I-Person
в O
1950 B-Date
году O
усомнился O
в O
том O
, O
что O
машина O
не O
может O
мыслить O
, O
и O
для O
проверки O
предложил O
свой O
знаменитый O
тест B-Object
. O

# text =  В 1954 году прошёл Джорджтаунский эксперимент.
В O
1954 B-Date_Experiment
году O
прошёл O
Джорджтаунский B-Experiment
эксперимент I-Experiment
. O

# text =   В его рамках демонстрировалась система, которая автоматически перевела 60 предложений с русского языка на французский.
В O
его O
рамках O
демонстрировалась O
система B-Object
, O
которая O
автоматически O
перевела O
60 O
предложений B-Subject
с O
русского B-Lang
языка B-Object
на O
французский B-Lang
. O

# text =   В 1960-е годы появились первые чат-боты, очень примитивные: в основном они перефразировали то, что говорил им собеседник-человек.
В O
1960-е B-Date_Result
годы O
появились O
первые O
чат B-Result
- I-Result
боты I-Result
, O
очень O
примитивные O
: O
в O
основном O
они O
перефразировали O
то O
, O
что O
говорил O
им O
собеседник O
- O
человек O
. O

# text =   Даже знаменитый чат-бот Женя Густман, который, как считается, прошёл одну из версий теста Тьюринга, сделал это не благодаря хитрым алгоритмам.
Даже O
знаменитый O
чат B-Result
- I-Result
бот I-Result
Женя I-Result
Густман I-Result
, O
который O
, O
как O
считается O
, O
прошёл O
одну O
из O
версий O
теста B-Result
Тьюринга I-Result
, O
сделал O
это O
не O
благодаря O
хитрым O
алгоритмам O
. O

# text =   Учёные пытались всё формализовать, построить формальную модель, онтологию, понятия, связи, общие правила синтаксического разбора и универсальную грамматику.
Учёные O
пытались O
всё O
формализовать O
, O
построить O
формальную B-Model
модель B-Model
, O
онтологию B-Result
, O
понятия B-Object
, O
связи B-Object
, O
общие O
правила O
синтаксического B-Method
разбора I-Method
и O
универсальную B-Result
грамматику I-Result
. O

# text =   Тогда возникла теория грамматик Хомского.
Тогда O
возникла O
теория B-Method
грамматик I-Method
Хомского I-Method
. O

# text =   Поэтому в 1980-е годы внимание переключилось на систему другого класса: на алгоритмы машинного обучения и так называемую корпусную лингвистику.
Поэтому O
в O
1980-е B-Date
годы O
внимание O
переключилось O
на O
систему O
другого O
класса B-Object
: O
на O
алгоритмы B-Method
машинного B-Method
обучения I-Method
и O
так O
называемую O
корпусную B-Science
лингвистику I-Science
. O

# text =   В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.
В O
1990-е B-Date
годы O
эта O
область O
получила O
очень O
мощный O
толчок O
благодаря O
развитию O
Всемирной B-Application
паутины I-Application
с O
большим O
количеством O
слабоструктурированного B-Object
текста I-Object
, O
по O
которому O
нужно O
было O
искать O
, O
его O
требовалось O
каталогизировать O
. O

# text =   В 2000-е анализ естественных языков начал применяться уже не только для поиска в Интернете, но и для решения разнообразных задач.
В O
2000-е O
анализ B-Method
естественных I-Method
языков B-Method
начал O
применяться O
уже O
не O
только O
для O
поиска O
в O
Интернете B-Application
, O
но O
и O
для O
решения O
разнообразных O
задач O
. O

# text =   Возникли модели, основанные на краудсорсинге: мы не только пытаемся что-то понять с помощью машины, а подключаем людей, которые за небольшую плату определяют, на каком языке написан текст.
Возникли O
модели B-Object
, O
основанные O
на O
краудсорсинге B-Method
: O
мы O
не O
только O
пытаемся O
что O
- O
то O
понять O
с O
помощью O
машины O
, O
а O
подключаем O
людей O
, O
которые O
за O
небольшую O
плату O
определяют O
, O
на O
каком O
языке O
написан O
текст O
. O

# text =   В некотором смысле начали возрождаться идеи использования формальных онтологий, но теперь онтологии крутятся вокруг краудсорсинговых баз знаний, в частности баз на основе Linked Open Data.
В O
некотором O
смысле O
начали O
возрождаться O
идеи O
использования O
формальных B-Object
онтологий I-Object
, O
но O
теперь O
онтологии B-Object
крутятся O
вокруг O
краудсорсинговых O
баз O
знаний O
, O
в O
частности O
баз O
на O
основе O
Linked B-InfoResource
Open I-InfoResource
Data I-InfoResource
. O

# text =   Это целый набор баз знаний, его центр — машиночитаемый вариант «Википедии» DBpedia, который тоже наполняется по краудсорсинговой модели.
Это O
целый O
набор O
баз O
знаний O
, O
его O
центр O
— O
машиночитаемый O
вариант O
« O
Википедии B-InfoResource
» O
DBpedia B-InfoResource
, O
который O
тоже O
наполняется O
по O
краудсорсинговой B-Model
модели I-Model
. O

# text =   В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.
В O
частности O
, O
семантический B-Method
анализ I-Method
( O
о O
чём O
документ O
? O
) O
, O
генерация B-Task
автоматической I-Task
аннотации I-Task
и O
автоматического B-Object
summary I-Object
, O
перевод B-Task
и O
создание B-Task
документов I-Task
. O

# text =   Все наверняка слышали об известном генераторе научных статей SCIgen, который создал статью «Корчеватель: Алгоритм типичной унификации точек доступа и избыточности».
Все O
наверняка O
слышали O
об O
известном O
генераторе O
научных O
статей O
SCIgen B-Technology
, O
который O
создал O
статью O
« O
Корчеватель O
: O
Алгоритм O
типичной O
унификации O
точек O
доступа O
и O
избыточности O
» O
. O

# text =   Но в случае с лентой такие рекомендации работают плохо: здесь постоянно возникает ситуация холодного старта.
Но O
в O
случае O
с O
лентой O
такие O
рекомендации O
работают O
плохо O
: O
здесь O
постоянно O
возникает O
ситуация B-Object
холодного I-Object
старта I-Object
. O

# text =   Поэтому применим классический воркэраунд для задачи холодного старта и построим систему контентных рекомендаций: попробуем научить машину понимать, о чём написан пост.
Поэтому O
применим O
классический O
воркэраунд B-Method
для O
задачи O
холодного B-Task
старта I-Task
и O
построим O
систему O
контентных O
рекомендаций O
: O
попробуем O
научить O
машину O
понимать O
, O
о O
чём O
написан O
пост O
. O

# text =   Соответственно, требуется метод семантического анализа.
Соответственно O
, O
требуется O
метод B-Method
семантического I-Method
анализа I-Method
. O

# text =   Тут поможет анализ эмоциональной окраски.
Тут O
поможет O
анализ B-Method
эмоциональной I-Method
окраски I-Method
. O

# text =   В частности, это Apache Tika, японская библиотека language-detection и одна из последних разработок — питоновский пакет Ldig, который как раз работает на инфинитиграммах.
В O
частности O
, O
это O
Apache B-Library
Tika I-Library
, O
японская O
библиотека O
language B-Library
- I-Library
detection I-Library
и O
одна O
из O
последних O
разработок O
— O
питоновский O
пакет O
Ldig B-Library
, O
который O
как O
раз O
работает O
на O
инфинитиграммах O
. O

# text =   Но если текст короткий, из одного предложения или нескольких слов, то классический подход, основанный на триграммах, очень часто ошибается.
Но O
если O
текст B-Object
короткий O
, O
из O
одного O
предложения B-Subject
или O
нескольких O
слов B-Subject
, O
то O
классический O
подход O
, O
основанный O
на O
триграммах B-Subject
, O
очень O
часто O
ошибается O
. O

# text =   Исправить ситуацию могут инфинитиграммы, но это новая область, далеко не для всех языков уже есть обученные и готовые классификаторы.
Исправить O
ситуацию O
могут O
инфинитиграммы B-Object
, O
но O
это O
новая O
область O
, O
далеко O
не O
для O
всех O
языков O
уже O
есть O
обученные O
и O
готовые O
классификаторы O
. O

# text =   Первый основан на так называемом фонетическом матчинге.
Первый O
основан O
на O
так O
называемом O
фонетическом B-Method
матчинге I-Method
. O

# text =   Альтернативный подход — так называемое редакционное расстояние, с помощью которого мы ищем в словаре максимально похожие слова-аналоги.
Альтернативный O
подход O
— O
так O
называемое O
редакционное B-Metric
расстояние I-Metric
, O
с O
помощью O
которого O
мы O
ищем O
в O
словаре O
максимально O
похожие O
слова O
- O
аналоги O
. O

# text =   Первая концепция — стемминг, мы пытаемся найти основу слова.
Первая O
концепция O
— O
стемминг B-Method
, O
мы O
пытаемся O
найти O
основу B-Subject
слова I-Subject
. O

# text =   Здесь используется подход affix stripping.
Здесь O
используется O
подход O
affix B-Method
stripping I-Method
. O

# text =   Есть известная реализация, так называемый стеммер Портера, или проект Snowball.
Есть O
известная O
реализация O
, O
так O
называемый O
стеммер B-Object
Портера I-TERM
, O
или O
проект O
Snowball B-Project
. O

# text =   Самый распространённый, наверное, инструмент — реализация в пакете Apache Lucene.
Самый O
распространённый O
, O
наверное O
, O
инструмент O
— O
реализация O
в O
пакете O
Apache B-Library
Lucene I-Library
. O

# text =   Вторая концепция, альтернатива стемминга — лемматизация.
Вторая O
концепция O
, O
альтернатива O
стемминга B-Method
— O
лемматизация B-Method
. O

# text =   Она пытается привести слово не к основе или корню, а к базовой, словарной форме — т. е. лемме.
Она O
пытается O
привести O
слово B-Subject
не O
к O
основе B-Subject
или O
корню B-Object
, O
а O
к O
базовой O
, O
словарной B-Subject
форме I-Subject
— O
т O
. O
  O
е O
. O
лемме B-Subject
. O

# text =   Существует множество реализаций, и тема очень хорошо проработана именно для user generated текстов, пользовательски зашумлённых текстов.
Существует O
множество O
реализаций O
, O
и O
тема B-Object
очень O
хорошо O
проработана O
именно O
для O
user B-Object
generated I-Object
текстов I-Object
, O
пользовательски O
зашумлённых O
текстов B-Object
. O

# text =   Теперь отобразим это в векторном пространстве, потому что почти все математические модели работают в векторных пространствах больших размерностей.
Теперь O
отобразим O
это O
в O
векторном B-Object
пространстве I-Object
, O
потому O
что O
почти O
все O
математические B-Model
модели B-Model
работают O
в O
векторных B-Object
пространствах I-Object
больших O
размерностей O
. O

# text =   Базовый подход, который используют многие модели, — метод "мешка слов".
Базовый O
подход O
, O
который O
используют O
многие O
модели O
, O
— O
метод B-Method
" I-Method
мешка I-Method
слов I-Method
" I-Method
. O

# text =   Доминирует так называемый TF-IDF.
Доминирует O
так O
называемый O
TF B-Metric
- I-Metric
IDF I-Metric
. O

# text =   Частоту слова (term frequency, TF) определяют по-разному.
Частоту B-Metric
слова B-Metric
( O
term B-Metric
frequency I-Metric
, O
TF B-Metric
) O
определяют O
по O
- O
разному O
. O

# text =   Определив TF в документе, мы перемножаем её с обратной частотой документа (inverse document frequency, IDF).
Определив O
TF B-Metric
в O
документе O
, O
мы O
перемножаем O
её O
с O
обратной B-Metric
частотой I-Metric
документа I-Metric
( O
inverse B-Metric
document I-Metric
frequency I-Metric
, O
IDF B-Metric
) O
. O

# text =   IDF обычно вычисляют как логарифм от числа документов в корпусе, разделённый на количество документов, где это слово представлено.
IDF B-Metric
обычно O
вычисляют O
как O
логарифм B-Object
от O
числа O
документов O
в O
корпусе B-Object
, O
разделённый O
на O
количество O
документов O
, O
где O
это O
слово B-Subject
представлено O
. O

# text =   Например, при анализе эмоциональной окраски очень важно, к чему относилось, условно говоря, слово «хороший» или «нет».
Например O
, O
при O
анализе B-Method
эмоциональной I-Method
окраски I-Method
очень O
важно O
, O
к O
чему O
относилось O
, O
условно O
говоря O
, O
слово B-Subject
« O
хороший O
» O
или O
« O
нет O
» O
. O

# text =   Тогда наряду с мешком слов поможет мешок N-грамм: мы добавляем в словарь не только слова, но и словосочетания.
Тогда O
наряду O
с O
мешком B-Method
слов I-Method
поможет O
мешок B-Method
N I-Method
- I-Method
грамм I-Method
: O
мы O
добавляем O
в O
словарь O
не O
только O
слова B-Subject
, O
но O
и O
словосочетания B-Subject
. O

# text =   Мы не будем вносить все словосочетания, потому что это приведёт к комбинаторному взрыву, но часто используемые статистически значимые пары или пары, соответствующие именованным сущностям, можно добавить, и это повысит качество работы итоговой модели.
Мы O
не O
будем O
вносить O
все O
словосочетания B-Subject
, O
потому O
что O
это O
приведёт O
к O
комбинаторному O
взрыву O
, O
но O
часто O
используемые O
статистически O
значимые O
пары O
или O
пары O
, O
соответствующие O
именованным B-Subject
сущностям I-Subject
, O
можно O
добавить O
, O
и O
это O
повысит O
качество O
работы O
итоговой O
модели B-Object
. O

# text =   Отчасти эти ситуации позволяют обработать методы построения "векторных представлений слов", например, знаменитый word2vec или более модные skip-gramm.
Отчасти O
эти O
ситуации O
позволяют O
обработать O
методы O
построения O
" O
векторных B-Subject
представлений I-Subject
слов I-Subject
" O
, O
например O
, O
знаменитый O
word2vec B-Model
или O
более O
модные O
skip B-Model
- I-Model
gramm I-Model
. O

# text =   Стандартные хеш-функции равномерно размазывают данные по пространству хешей.
Стандартные O
хеш B-Method
- I-Method
функции I-Method
равномерно O
размазывают O
данные O
по O
пространству O
хешей O
. O

# text =   Локально-чувствительный хеш похожие объекты поместит в пространстве объектов близко.
Локально B-Method
- I-Method
чувствительный I-Method
хеш I-Method
похожие O
объекты O
поместит O
в O
пространстве O
объектов O
близко O
. O

# text =   Мы выбираем случайный базис из случайных векторов.
Мы O
выбираем O
случайный O
базис B-Object
из O
случайных B-Object
векторов I-Object
. O

# text =   Задача семантического анализа достаточно старая.
Задача O
семантического B-Task
анализа B-Task
достаточно O
старая O
. O

# text =   Современный подход — анализ семантики без учителя, поэтому его называют анализом скрытой (латентной) семантики.
Современный O
подход O
— O
анализ B-Method
семантики I-Method
без I-Method
учителя I-Method
, O
поэтому O
его O
называют O
анализом B-Method
скрытой I-Method
( I-Method
латентной I-Method
) I-Method
семантики I-Method
. O

# text =   Исторически первый подход к латентно-семантическому анализу — это латентно-семантическое индексирование.
Исторически O
первый O
подход O
к O
латентно B-Method
- I-Method
семантическому I-Method
анализу B-Method
— O
это O
латентно B-Method
- I-Method
семантическое I-Method
индексирование I-Method
. O

# text =   Мы уже использовали для решения задач коллаборативных рекомендаций хорошо зарекомендовавшие себя техники факторизации матриц.
Мы O
уже O
использовали O
для O
решения O
задач B-Task
коллаборативных I-Task
рекомендаций I-Task
хорошо O
зарекомендовавшие O
себя O
техники O
факторизации O
матриц O
. O

# text =   В чём суть факторизации?
В O
чём O
суть O
факторизации B-Method
? O

# text =   Одной из альтернатив стал так называемый вероятностный латентно-семантический индекс.
Одной O
из O
альтернатив O
стал O
так O
называемый O
вероятностный B-Metric
латентно I-Metric
- I-Metric
семантический I-Metric
индекс B-Metric
. O

# text =   Важно понять, что техника вероятностного латентно-семантического индекса — это техника факторизации матрицы.
Важно O
понять O
, O
что O
техника B-Method
вероятностного I-Method
латентно I-Method
- I-Method
семантического I-Method
индекса B-Method
— O
это O
техника I-Method
факторизации I-Method
матрицы I-Method
. O

# text =   По сравнению с классической факторизацией на основе сингулярного разложения у вероятностной генерирующей модели есть важное преимущество.
По O
сравнению O
с O
классической B-Method
факторизацией I-Method
на O
основе O
сингулярного B-Object
разложения I-Object
у O
вероятностной O
генерирующей O
модели O
есть O
важное O
преимущество O
. O

# text =   Для этого используется перплексия.
Для O
этого O
используется O
перплексия B-Method
. O

# text =   Есть так называемый EM-алгоритм.
Есть O
так O
называемый O
EM B-Method
- I-Method
алгоритм I-Method
. O
