Основанный на глубоком обучении подход для решения задач анализа текста стал активно набирать обороты, когда в 2017 году была опубликована статья Attention Is All You Need [2], представившая миру механизм внимания, хорошо подходящий для работы с текстом, позволяющий прослеживать сложные связи между словами.

Размер нейронных сетей с архитектурой Transformer значительно превышает размер своих предшественников - рекуррентных сетей. Даже небольшие BERT (Bidirectional Encoder Representations from Transformers) [3], модели могут содержать десятки миллионов параметров, из-за чего их обучение “с нуля” может занять значительное количество времени и потребовать большого количества экземпляров для обучения.

В связи с этим, широкое распространение получила техника Fine Tuning, основанная на том, что вначале создается экземпляр базовой модели, предобученной на стандартной задаче для работы с текстом, такой как маскирование, c использованием больших корпусов текста, а затем уже этот базовый экземпляр дообучается на решении самых разных частных задач. Эта техника требует меньшего времени обучения, однако не решает проблему.

Особенно остро она проявляется для генеративных моделей, содержащих миллиарды параметров, так называемых LLM или GPT. Их качественное обучение задействует значительные вычислительные ресурсы, что может стоить достаточно дорого.

Чтобы избежать высоких затрат на обучение, часто используют более простой подход под названием Prompt Engineering [4], когда модели передается инструкция, написанная человеком, в которой описывается задача, которую предстоит решать. Так, например, в ней можно дать указания на перевод текста с одного языка на другой.

Преимуществом данной техники является полное отсутствие необходимости в обучении модели, ее веса замораживаются. При каждом запуске ей передается подготовленная инструкция с аргументами, по которым нужно сделать предсказание. Существенным недостатком является сложность в подборе оптимальной инструкции, поскольку эта задача ложится целиком на человека. Чем больше промпт, тем сложнее модели работать со всем контекстом, что влечет к более низким результатам.

Например, GPT-3 175B с Few-Shot Prompting показал на 17.5 очков меньше, чем T5-XXL (71.8 vs. 89.3), к которому был применен Fine Tuning, несмотря на то что первая модель в 16 раз больше второй [6].

В связи с этим, в 2021 году была разработана новая техника под названием Prompt Tuning, речь о которой и пойдет далее.

1. Описание Prompt Tuning.

Данная техника во многом похожа на Prompt Engineering. Существенным отличием является то, что промпт в этом случае будет формироваться не человеком (hard-prompt), а искусственным интеллектом (soft-prompt).

Рассмотрим применение данной техники на примере задачи классификации с использованием Text-To-Text генерации [6].

Вместо классической постановки задачи, Pr(y∣X),Pr(y∣X), где XX является последовательностью токенов, а yy - меткой одного из классов, мы представим это в виде Prθ(Y∣X), где Y - последовательность токенов, отражающих метку класса, θ - фиксированная совокупность параметров предобученного трансформера. Таким образом, мы оставим веса модели замороженными, что является существенным различием с Fine Tuning. Также обозначим токены промпта за P.

Важно отметить, что в случае с Prompt Engineering, выражение примет вид, то есть произойдет конкатенация последовательностей токенов P и X, после чего полная последовательность перейдет на вход модели, а именно на Embedding слой, параметризованный θθ. Данный слой инициализирует каждый токен embedding'ом (вектором) длины ee.

Токены промпта будут векторизованы замороженными параметрами модели θ. При этом, сам промпт эмпирически составлен человеком, а значит с большой вероятностью данное векторное представление инструкции будет неоптимальным.

Использование Prompt Tuning подразумевает задействовать формулу Prθ;θP(Y∣[P;X]), то есть векторизация промпта будет происходить за счет отдельного набора параметров, которые будут оптимизироваться градиентным спуском в рамках обучения. Иными словами, обучаться будет не модель, а промпт. Стоит отметить, что обратное распространение все равно должно пройти все слои модели, чтобы донести необходимые дельты для параметров промпта.

Итак, по набору входных токенов с использованием фиксированных параметров модели θ будет сформирована матрица векторизованных токенов. Затем, soft prompt PP будет векторизован весами, получим Pe. Далее, получаем конкатенацию вышеуказанных матриц [Pe;Xe]∈R(p+n)×e, которая пойдет на следующий после Embedding слой LLM.

2. Prompt Ensembling.

При использовании данной техники одну и ту же модель можно параллельно обучать различным задачам, передавая различные промпты. Аналогично можно поступать и в inference режиме. Это очень важное преимущество для систем, решающих сразу несколько задач, поскольку в оперативную память необходимо поместить всего одну модель, в которую будет передаваться промпт, связанный с конкретной задачей, который может быть легко заменен на промпт для другой задачи.

3. Гиперпараметры промпта.

Стоит отметить, что человек не принимает участие в инициализации soft промпта, его длина и начальные значения являются гиперпараметрами. Было проведено множество измерений применения данной техники на серии моделей T5 с различными длинами промпта, начальными значениями, методами предобучения, количеству шагов LM адаптации. Результаты представлены ниже:

Техника Prompt Tuning показывает действительно многообещающие результаты для моделей значительного размера.
Используя данный подход, можно провести значительно более быстрое обучение в сравнении со стандартным Fine Tuning и получить более качественные результаты в сравнении с Prompt Engineering. Более того, для отдельных задач результаты Prompt Tuning даже превосходят результаты Fine Tuning.
