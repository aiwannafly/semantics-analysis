# text =  Энкодер предложений (sentence encoder) – это модель, которая сопоставляет коротким текстам векторы в многомерном пространстве, причём так, что у текстов, похожих по смыслу, и векторы тоже похожи.
Энкодер B-TERM
предложений I-TERM
( O
sentence B-TERM
encoder I-TERM
) O
– O
это O
модель O
, O
которая O
сопоставляет O
коротким O
текстам O
векторы O
в O
многомерном O
пространстве O
, O
причём O
так O
, O
что O
у O
текстов O
, O
похожих O
по O
смыслу O
, O
и O
векторы O
тоже O
похожи O
. O

# text =  Обычно для этой цели используются нейросети, а полученные векторы называются эмбеддингами.
Обычно O
для O
этой O
цели O
используются O
нейросети B-TERM
, O
а O
полученные O
векторы O
называются O
эмбеддингами B-TERM
. O

# text =  Они полезны для кучи задач, например, few-shot классификации текстов, семантического поиска, или оценки качества перефразирования.
Они O
полезны O
для O
кучи O
задач O
, O
например O
, O
few B-TERM
- I-TERM
shot I-TERM
классификации I-TERM
текстов I-TERM
, O
семантического B-TERM
поиска I-TERM
, O
или O
оценки B-TERM
качества I-TERM
перефразирования I-TERM
. O

# text =  Самой качественной моделью оказался mUSE, самой быстрой из предобученных – FastText, а по балансу скорости и качества победил rubert-tiny2.
Самой O
качественной O
моделью O
оказался O
mUSE B-TERM
, O
самой O
быстрой O
из O
предобученных O
– O
FastText B-TERM
, O
а O
по O
балансу O
скорости O
и O
качества O
победил O
rubert B-TERM
- I-TERM
tiny2 I-TERM
. O

# text =  Первой известной попыткой системно сравнить английские эмбеддинги предложений был SentEval, сочетающий чисто лингвистические задачи со вполне прикладными.
Первой O
известной O
попыткой O
системно O
сравнить O
английские O
эмбеддинги B-TERM
предложений O
был O
SentEval B-TERM
, O
сочетающий O
чисто O
лингвистические O
задачи O
со O
вполне O
прикладными O
. O

# text =  Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк "сложных" NLP задач; фокус на дообучаемых моделях.
Для O
русского B-TERM
языка O
тоже O
было O
создано O
немало O
разного O
рода O
бенчмарков O
NLU B-TERM
моделей O
: O
RussianSuperGLUE B-TERM
: O
бенчмарк O
" O
сложных O
" O
NLP B-TERM
задач I-TERM
; O
фокус O
на O
дообучаемых O
моделях O
. O

# text = MOROCCO: RussianSuperGLUE + оценка производительности, довольно трудновоспроизводимый бенчмарк.
MOROCCO O
: O
RussianSuperGLUE B-TERM
+ O
оценка O
производительности O
, O
довольно O
трудновоспроизводимый O
бенчмарк O
. O

# text =  RuSentEval: бенчмарк BERT-подобных энкодеров предложений на лингвистических задачах.
RuSentEval B-TERM
: O
бенчмарк O
BERT B-TERM
- I-TERM
подобных I-TERM
энкодеров I-TERM
предложений I-TERM
на O
лингвистических O
задачах O
. O

# text =  SentEvalRu и deepPavlovEval: два хороших, но давно не обновлявшихся прикладных бенчмарка.
SentEvalRu B-TERM
и O
deepPavlovEval B-TERM
: O
два O
хороших O
, O
но O
давно O
не O
обновлявшихся O
прикладных O
бенчмарка O
. O

# text =  С тех пор появилось много новых русскоязычных моделей, включая rubert-tiny2, поэтому и бенчмарк пришло время обновить.
С O
тех O
пор O
появилось O
много O
новых O
русскоязычных O
моделей O
, O
включая O
rubert B-TERM
- I-TERM
tiny2 I-TERM
, O
поэтому O
и O
бенчмарк O
пришло O
время O
обновить O
. O

# text =  В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.
В O
основу O
бенчмарка O
легли O
BERT B-TERM
- I-TERM
подобные I-TERM
модели I-TERM
: O
sbert_large_nlu_ru B-TERM
, O
sbert_large_mt_nlu_ru B-TERM
, O
и O
ruRoberta B-TERM
- I-TERM
large I-TERM
от O
Сбера B-TERM
; O
rubert B-TERM
- I-TERM
base I-TERM
- I-TERM
cased I-TERM
- I-TERM
sentence I-TERM
, O
rubert B-TERM
- I-TERM
base I-TERM
- I-TERM
cased I-TERM
- I-TERM
conversational I-TERM
, O
distilrubert B-TERM
- I-TERM
tiny I-TERM
- I-TERM
cased I-TERM
- I-TERM
conversational I-TERM
, O
и O
distilrubert B-TERM
- I-TERM
base I-TERM
- I-TERM
cased I-TERM
- I-TERM
conversational I-TERM
от O
DeepPavlov B-TERM
; O
мои O
   O
rubert B-TERM
- I-TERM
tiny I-TERM
и O
rubert B-TERM
- I-TERM
tiny2 I-TERM
; O
мультиязычные O
LaBSE B-TERM
( O
плюс O
урезанная O
версия O
LaBSE B-TERM
- I-TERM
en I-TERM
- I-TERM
ru I-TERM
) O
и O
старый O
добрый O
bert B-TERM
- I-TERM
base I-TERM
- I-TERM
multilingual I-TERM
- I-TERM
cased I-TERM
. O

# text =  Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.
Кроме O
этого O
, O
я O
добавил O
в O
бенчмарк O
разные O
T5 B-TERM
модели I-TERM
, O
т.к. O
они O
тоже O
должны O
хорошо O
понимать O
тексты O
: O
мои O
rut5-small B-TERM
, O
rut5-base B-TERM
, O
rut5-base B-TERM
- I-TERM
multitask I-TERM
, O
и O
rut5-base B-TERM
- I-TERM
paraphraser I-TERM
, O
и O
Сберовские B-TERM
ruT5-base B-TERM
и O
ruT5-large B-TERM
. O

# text =  Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.
Помимо O
BERTов O
и O
T5 O
, O
я O
включил O
в O
бенчмарк O
большие O
мультиязычные O
модели O
Laser B-TERM
от O
FAIR B-TERM
и O
USE B-TERM
- I-TERM
multilingual I-TERM
- I-TERM
large I-TERM
от O
Google B-TERM
. O

# text =  В качестве быстрого бейзлайна, я добавил FastText, а именно, geowac_tokens_none_fasttextskipgram_300_5_2020  с RusVectores, а также его сжатую версию.
В O
качестве O
быстрого O
бейзлайна O
, O
я O
добавил O
FastText B-TERM
, O
а O
именно O
, O
geowac_tokens_none_fasttextskipgram_300_5_2020 B-TERM
с O
RusVectores B-TERM
, O
а O
также O
его O
сжатую O
версию O
. O

# text =  Наконец, я добавил парочку "моделей", которые вообще не выучивают никаких параметров, а просто используют HashingVectorizer для превращения текста в вектор признаков.
Наконец O
, O
я O
добавил O
парочку O
" O
моделей O
" O
, O
которые O
вообще O
не O
выучивают O
никаких O
параметров O
, O
а O
просто O
используют O
HashingVectorizer B-TERM
для O
превращения O
текста O
в O
вектор O
признаков O
. O

# text =  Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.
Это O
доработанная O
версия O
rubert B-TERM
- I-TERM
tiny I-TERM
: O
я O
расширил O
словарь O
модели O
c O
30К O
до O
80К O
токенов O
, O
увеличил O
максимальную O
длину O
текста O
с O
512 O
до O
2048 O
токенов O
, O
и O
дообучил O
модель O
на O
комбинации O
задач O
masked B-TERM
language I-TERM
modelling I-TERM
, O
natural B-TERM
language I-TERM
inference I-TERM
, O
и O
аппроксимации B-TERM
эмбеддингов I-TERM
LaBSE I-TERM
. O

# text =  В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.
В O
новой O
версии O
бенчмарка O
я O
оставил O
всё O
те O
же O
10 O
задач O
, O
что O
и O
в O
прежней O
, O
но O
слегка O
изменил O
формат O
некоторых O
из O
них O
: O
Semantic B-TERM
text I-TERM
similarity I-TERM
( O
STS B-TERM
) O
на O
основе O
переведённого O
датасета O
STS B-TERM
- I-TERM
B I-TERM
; O
Paraphrase B-TERM
identification I-TERM
( O
PI B-TERM
) O
на O
основе O
датасета O
paraphraser.ru B-TERM
; O
Natural B-TERM
language I-TERM
inference I-TERM
( O
NLI B-TERM
) O
на O
датасете O
XNLI B-TERM
; O
Sentiment B-TERM
analysis I-TERM
( O
SA B-TERM
) O
на O
данных O
SentiRuEval2016 B-TERM
. O

# text =  В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.
В O
прошлой O
версии O
бенчмарка O
я O
собрал O
кривые O
тестовые O
выборки O
, O
поэтому O
этот O
датасет O
я O
переделал O
; O
Toxicity B-TERM
identification I-TERM
( O
TI B-TERM
) O
на O
датасете B-TERM
токсичных I-TERM
комментариев I-TERM
из O
OKMLCup B-TERM
; O
Inappropriateness B-TERM
identification I-TERM
( O
II B-TERM
) O
на O
датасете B-TERM
Сколтеха I-TERM
; O
Intent B-TERM
classification I-TERM
( O
IC B-TERM
) O
и O
её O
кросс O
- O
язычная O
версия O
ICX B-TERM
на O
датасете O
NLU B-TERM
- I-TERM
evaluation I-TERM
- I-TERM
data I-TERM
, O
который O
я O
автоматически O
перевёл O
на O
русский B-TERM
. O

# text =  В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.
В O
IC B-TERM
классификатор I-TERM
обучается O
на O
русских B-TERM
данных O
, O
а O
в O
ICX B-TERM
– O
на O
английских B-TERM
, O
а O
тестируется O
в O
обоих O
случаях O
на O
русских O
. O

# text =  Распознавание именованных сущностей () на датасетах factRuEval-2016E1) и RuDReC (NE2).
Распознавание O
именованных O
сущностей O
( O
) O
на O
датасетах O
factRuEval-2016E1 B-TERM
) O
и O
RuDReC B-TERM
( O
NE2 B-TERM
) O
. O

# text =  Эти две задачи требуют получать эмбеддинги отдельных токенов, а не целых предложений; поэтому модели USE и Laser, не выдающие эмбеддинги токенов "из коробки", в оценке этих задач не участвовали.
Эти O
две O
задачи O
требуют O
получать O
эмбеддинги O
отдельных O
токенов O
, O
а O
не O
целых O
предложений O
; O
поэтому O
модели O
USE B-TERM
и O
Laser B-TERM
, O
не O
выдающие O
эмбеддинги O
токенов O
" O
из O
коробки O
" O
, O
в O
оценке O
этих O
задач O
не O
участвовали O
. O

# text =  В задачах STS, PI и NLI оценивается степень связи двух текстов.
В O
задачах O
STS B-TERM
, O
PI B-TERM
и O
NLI B-TERM
оценивается O
степень O
связи O
двух O
текстов O
. O

# text =  Хороший энкодер предложений должен отражать эту степень в их косинусной близости, поэтому для STS и PI мы измеряем качество как Спирмановскую корреляцию косинусной близости и человеческих оценок сходства.
Хороший O
энкодер O
предложений O
должен O
отражать O
эту O
степень O
в O
их O
косинусной B-TERM
близости B-TERM
, O
поэтому O
для O
STS B-TERM
и O
PI B-TERM
мы O
измеряем O
качество O
как O
Спирмановскую B-TERM
корреляцию I-TERM
косинусной O
близости O
и O
человеческих O
оценок O
сходства O
. O

# text =  Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).
Для O
NLI B-TERM
я O
обучил O
трёхклассовую O
( O
entail O
/ O
contradict O
/ O
neutral O
) O
логистическую B-TERM
регрессию I-TERM
поверх O
косинусной B-TERM
близости I-TERM
, O
и O
измеряю O
её O
точность B-TERM
( O
accuracy B-TERM
) O
. O

# text =  Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).
Для O
задач O
бинарной O
классификации O
TI B-TERM
и O
II B-TERM
я O
измеряю O
ROC B-TERM
AUC I-TERM
, O
а O
в O
задачах O
многоклассовой O
классификации O
SA B-TERM
, O
IC B-TERM
и O
ICX B-TERM
– O
точность B-TERM
( O
accuracy B-TERM
) O
. O

# text =  Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.
Для O
всех O
задач O
классификации B-TERM
я O
обучаю O
логистическую B-TERM
регрессию I-TERM
либо O
KNN B-TERM
поверх O
эмбеддингов O
предложений O
, O
и O
выбираю O
лучшую O
модель O
из O
двух O
. O

# text =  Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О. 
Для O
задач O
NER B-TERM
я O
классифицировал O
токены O
логистической B-TERM
регрессией I-TERM
поверх O
их O
эмбеддингов O
, O
и O
измерял O
macro B-TERM
F1 I-TERM
по O
всем O
классам O
токенов O
, O
кроме O
О O
.

# text = Поскольку разные модели токенизируют тексты по-разному, я токенизировал все тексты razdel'ом, и вычислял эмбеддинг слова как средний эмбеддинг его токенов.
Поскольку O
разные O
модели O
токенизируют O
тексты O
по O
- O
разному O
, O
я O
токенизировал O
все O
тексты O
razdel'ом B-TERM
, O
и O
вычислял O
эмбеддинг O
слова O
как O
средний O
эмбеддинг O
его O
токенов O
. O

# text =  Единого победителя нет, но MUSE, sbert_large_mt_nlu_ru и rubert-base-cased-sentence взяли по многу призовых мест.
Единого O
победителя O
нет O
, O
но O
MUSE B-TERM
, O
sbert_large_mt_nlu_ru B-TERM
и O
rubert B-TERM
- I-TERM
base I-TERM
- I-TERM
cased I-TERM
- I-TERM
sentence I-TERM
взяли O
по O
многу O
призовых O
мест O
. O

# text =  Удивительно, но модели T5 очень хорошо показали себя на задачах NER.
Удивительно O
, O
но O
модели O
T5 B-TERM
очень O
хорошо O
показали O
себя O
на O
задачах O
NER B-TERM
. O


# text =  Самыми качественными энкодерами предложений оказались мультиязычные MUSE, LaBSE и Laser.
Самыми O
качественными O
энкодерами O
предложений O
оказались O
мультиязычные O
MUSE B-TERM
, O
LaBSE B-TERM
и O
Laser B-TERM
. O


# text =  Но выбирать стоит из Парето-оптимальных моделей: таких, что ни одна другая модель не превосходит их по всем критериям.
Но O
выбирать O
стоит O
из O
Парето B-TERM
- I-TERM
оптимальных I-TERM
моделей I-TERM
: O
таких O
, O
что O
ни O
одна O
другая O
модель O
не O
превосходит O
их O
по O
всем O
критериям O
. O

# text =  Из 25 моделей только 12 Парето-оптимальны:MUSE, rubert-tiny2, FT_geowac, Hashing_1000_char и Hashing_1000 обладают самым лучшим качеством для своей скорости на CPU; MUSE, LaBSE, rubert-tiny2, и distilbert-tiny обладают наилучшим качеством для своей скорости на GPU;MUSE, LaBSE, rubert-tiny2, rubert-tiny, FT_geowac_21mb, и Hashing_1000_char обладают наилучшим качеством для своего размера.
Из O
25 O
моделей O
только O
12 O
Парето O
- O
оптимальны O
: O
MUSE B-TERM
, O
rubert B-TERM
- I-TERM
tiny2 I-TERM
, O
FT_geowac B-TERM
, O
Hashing_1000_char B-TERM
и O
Hashing_1000 B-TERM
обладают O
самым O
лучшим O
качеством O
для O
своей O
скорости O
на O
CPU O
; O
MUSE B-TERM
, O
LaBSE B-TERM
, O
rubert B-TERM
- I-TERM
tiny2 I-TERM
, O
и O
distilbert B-TERM
- I-TERM
tiny I-TERM
обладают O
наилучшим O
качеством O
для O
своей O
скорости O
на O
GPU O
; O
MUSE B-TERM
, O
LaBSE B-TERM
, O
rubert B-TERM
- I-TERM
tiny2 I-TERM
, O
rubert B-TERM
- I-TERM
tiny I-TERM
, O
FT_geowac_21 B-TERM
mb O
, O
и O
Hashing_1000_char B-TERM
обладают O
наилучшим O
качеством O
для O
своего O
размера O
. O

# text =  Актуальный лидерборд смотрите в репозитории: https://github.com/avidale/encodechka
Актуальный O
лидерборд O
смотрите O
в O
репозитории O
: O
https://github.com/avidale/encodechka B-TERM
. O